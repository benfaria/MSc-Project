{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Post-Proc - Reject Option Classifier\n",
    "%matplotlib inline\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy  as np\n",
    "import matplotlib.pyplot as plt\n",
    "# Import IBM's AI Fairness tooolbox\n",
    "from aif360.datasets      import BinaryLabelDataset\n",
    "from aif360.datasets      import AdultDataset, GermanDataset, CompasDataset\n",
    "from aif360.metrics       import ClassificationMetric, BinaryLabelDatasetMetric\n",
    "from aif360.metrics.utils import compute_boolean_conditioning_vector\n",
    "from aif360.algorithms.postprocessing.reject_option_classification import RejectOptionClassification\n",
    "from common_utils         import compute_metrics\n",
    "# Import scikit-learn core slibraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble        import RandomForestClassifier\n",
    "from sklearn.linear_model    import LogisticRegression\n",
    "from sklearn.preprocessing   import StandardScaler,MinMaxScaler\n",
    "from sklearn.metrics         import accuracy_score\n",
    "from sklearn.metrics         import balanced_accuracy_score\n",
    "from tqdm import tqdm\n",
    "from IPython.display   import Markdown, display\n",
    "from ipywidgets import interactive, FloatSlider\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the cleaned Taiwan-Credit-Card-Cleaned-Marriage dataset\n",
    "Taiwan_df = pd.read_csv('./input/Taiwan-Credit-Card-Cleaned-GENDER.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set privileged (1)/ unprivileged (0)/ favourable (1) / unfavourable values (0)\n",
    "protected_attr      = 'GENDER'\n",
    "priv_grp            = 1  # Males \n",
    "unpriv_grp          = 0  # Females  \n",
    "lab                 = 'DEFAULT'\n",
    "fav_label           = 1 # Will not default next month\n",
    "unfav_label         = 0 # Will default next month\n",
    "privileged_groups   = [{protected_attr: priv_grp}]   # Males\n",
    "unprivileged_groups = [{protected_attr: unpriv_grp}] # Females\n",
    "# Upper and lower bound on the fairness metric used\n",
    "metric_ub = 0.05\n",
    "metric_lb = -0.05\n",
    "allowed_metrics = [\"Statistical parity difference\",\n",
    "                   \"Average odds difference\",\n",
    "                   \"Equal opportunity difference\"]\n",
    "metric_name = \"Statistical parity difference\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the features and label splits\n",
    "X = Taiwan_df.drop(lab,axis=1)\n",
    "y = Taiwan_df[lab]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Binary Label Dataset to use with AIF360 APIs\n",
    "Taiwan_bld = BinaryLabelDataset(df=pd.concat((X, y), axis=1),\n",
    "                                label_names=[lab], protected_attribute_names=[protected_attr],\n",
    "                                favorable_label=fav_label, unfavorable_label=unfav_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the dataset and split into train and test\n",
    "Taiwan_orig_train, Taiwan_orig_vt   = Taiwan_bld.split([0.8])    # , shuffle=True)\n",
    "Taiwan_orig_valid, Taiwan_orig_test = Taiwan_orig_vt.split([0.5])# , shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy for predicting the Sensitive Variable before bias transformation:\n",
      "Biased Logistic regression validation accuracy: 0.5065\n",
      "Biased Random Forest       validation accuracy: 0.5156666666666667\n",
      "\n",
      "Biased Balanced accuracy\n",
      "Biased Logistic regression balanced accuracy  : 0.5008655556202553\n",
      "Biased Random Forest       balanced accuracy  : 0.5102468717092996\n"
     ]
    }
   ],
   "source": [
    "# First test whether it is possible to predict the Sensitive Variable from the training dataset\n",
    "Taiwan_train_df, d = Taiwan_orig_train.convert_to_dataframe(de_dummy_code=False, sep='=', set_category=False)\n",
    "Taiwan_test_df, d  = Taiwan_orig_vt.convert_to_dataframe(de_dummy_code=False, sep='=', set_category=False)\n",
    "X_se_train = Taiwan_train_df.drop(protected_attr,axis=1)\n",
    "y_se_train = Taiwan_train_df[protected_attr]\n",
    "X_se_test  = Taiwan_test_df.drop(protected_attr,axis=1)\n",
    "y_se_test  = Taiwan_test_df[protected_attr]\n",
    "\n",
    "Se_BiasedLogModel = LogisticRegression(random_state=101)\n",
    "Se_BiasedRfcModel = RandomForestClassifier(n_estimators=100,max_depth=4,random_state=101)\n",
    "Se_BiasedLogModel.fit(X_se_train, y_se_train) \n",
    "Se_BiasedRfcModel.fit(X_se_train, y_se_train) \n",
    "\n",
    "yseLog_pred =  Se_BiasedLogModel.predict(X_se_test)\n",
    "yseRfc_pred =  Se_BiasedRfcModel.predict(X_se_test)\n",
    "# Now test whether we can predict Gender from the test dataset\n",
    "print('Model Accuracy for predicting the Sensitive Variable before bias transformation:')\n",
    "print(f\"Biased Logistic regression validation accuracy: {Se_BiasedLogModel.score(X_se_test, y_se_test)}\")\n",
    "print(f\"Biased Random Forest       validation accuracy: {Se_BiasedRfcModel.score(X_se_test, y_se_test)}\")\n",
    "print('')\n",
    "print('Biased Balanced accuracy')\n",
    "print(f\"Biased Logistic regression balanced accuracy  : {balanced_accuracy_score(y_se_test, yseLog_pred)}\")\n",
    "print(f\"Biased Random Forest       balanced accuracy  : {balanced_accuracy_score(y_se_test, yseRfc_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of instances           : 3000.0\n",
      "Base Rate                     : 0.779\n",
      "Consistency                   : [0.73886667]\n",
      "Disparate Impact              : 1.0691643472561294\n",
      "Mean Difference               : 0.05197150525354044\n",
      "Statistical Parity Difference : 0.05197150525354044\n"
     ]
    }
   ],
   "source": [
    "metric_test_bld = BinaryLabelDatasetMetric(Taiwan_orig_test,\n",
    "                                           unprivileged_groups=unprivileged_groups,\n",
    "                                           privileged_groups=privileged_groups)\n",
    "print('Number of instances           :', metric_test_bld.num_instances())\n",
    "print('Base Rate                     :', metric_test_bld.base_rate())\n",
    "print('Consistency                   :', metric_test_bld.consistency())\n",
    "print('Disparate Impact              :', metric_test_bld.disparate_impact())\n",
    "print('Mean Difference               :', metric_test_bld.mean_difference())\n",
    "print('Statistical Parity Difference :', metric_test_bld.statistical_parity_difference()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train logistic regression and random forest classifier on the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Biased training dataset - model scores"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Biased Logistic regression validation accuracy: 0.807\n",
      "Biased Random Forest       validation accuracy: 0.8096666666666666\n",
      "\n",
      "Biased Logistic regression balanced accuracy  : 0.6007241878750259\n",
      "Biased Random forest balanced accuracy        : 0.6180156352612024\n"
     ]
    }
   ],
   "source": [
    "#Train Logistic Regression and Random Forest Classifiers on original training data\n",
    "scale_orig          = MinMaxScaler()\n",
    "X_train             = scale_orig.fit_transform(Taiwan_orig_train.features)\n",
    "y_train             = Taiwan_orig_train.labels.ravel()\n",
    "\n",
    "BiasedLogModel      = LogisticRegression(random_state=101)\n",
    "BiasedRfcModel      = RandomForestClassifier(n_estimators=100,max_depth=4,random_state=101)\n",
    "\n",
    "BiasedLogModel.fit(X_train, y_train)\n",
    "BiasedRfcModel.fit(X_train, y_train)\n",
    "\n",
    "BiasedLogPrediction = BiasedLogModel.predict(X_train)\n",
    "BiasedRfcPrediction = BiasedRfcModel.predict(X_train)\n",
    "\n",
    "# Determine the baseline model accuracy for Logistic Regression and Random Forest Classifiers\n",
    "display(Markdown(\"#### Biased training dataset - model scores\"))\n",
    "print('Biased Logistic regression validation accuracy:', BiasedLogModel.score(X_train, y_train))\n",
    "print('Biased Random Forest       validation accuracy:', BiasedRfcModel.score(X_train, y_train))\n",
    "print('')\n",
    "print('Biased Logistic regression balanced accuracy  :', balanced_accuracy_score(y_train, BiasedLogPrediction))\n",
    "print('Biased Random forest balanced accuracy        :', balanced_accuracy_score(y_train, BiasedRfcPrediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a numpy array pos_ind of all the '1s' (positive class index) to use for the test data.   \n",
    "# Update a COPY of the training dataset labels with the predicted labels. \n",
    "LogTrain_pred        = Taiwan_orig_train.copy(deepcopy=True)\n",
    "RfcTrain_pred        = Taiwan_orig_train.copy(deepcopy=True)\n",
    "LogTrain_pred.labels = BiasedLogPrediction\n",
    "RfcTrain_pred.labels = BiasedRfcPrediction\n",
    "# At this point we have copies of the Training dataset, whose labels are modified by \n",
    "# the Logistic Regression and Random Forest classifier predictions respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Use BiasedLogModel and BiasedRfcModel on the test and validation data and get scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a numpy array pos_ind of all the '1s' (positive class index) to use for the test data.   \n",
    "pos_log_ind = np.where(BiasedLogModel.classes_ == Taiwan_orig_valid.favorable_label)[0][0]\n",
    "pos_rfc_ind = np.where(BiasedRfcModel.classes_ == Taiwan_orig_valid.favorable_label)[0][0]\n",
    "\n",
    "# Obtain scores for Validation sets using the BiasedLogModel\n",
    "LogValid_pred = Taiwan_orig_valid.copy(deepcopy=True) # Create a copy of the original Validation dataset\n",
    "RfcValid_pred = Taiwan_orig_valid.copy(deepcopy=True) # Create a copy of the original Validation dataset\n",
    "\n",
    "X_log_valid = scale_orig.transform(LogValid_pred.features)\n",
    "y_log_valid = LogValid_pred.labels\n",
    "\n",
    "X_rfc_valid = scale_orig.transform(RfcValid_pred.features)\n",
    "y_rfc_valid = RfcValid_pred.labels\n",
    "\n",
    "# Update a COPY of the validation dataset labels with the predicted labels.\n",
    "LogValid_pred.scores = BiasedLogModel.predict_proba(X_log_valid)[:,pos_log_ind].reshape(-1,1)\n",
    "RfcValid_pred.scores = BiasedRfcModel.predict_proba(X_rfc_valid)[:,pos_rfc_ind].reshape(-1,1)\n",
    "# At this point we have copies of the Validation dataset, whose labels are modified by \n",
    "# the Logistic Regression and Random Forest classifier predictions respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a numpy array pos_ind of all the '1s' (positive class index) to use for the test data.   \n",
    "pos_log_indx = np.where(BiasedLogModel.classes_ == Taiwan_orig_test.favorable_label)[0][0]\n",
    "pos_rfc_indx = np.where(BiasedRfcModel.classes_ == Taiwan_orig_test.favorable_label)[0][0]\n",
    "\n",
    "# Obtain scores for the Test dataset using the BiasedLogModel\n",
    "LogTest_pred = Taiwan_orig_test.copy(deepcopy=True) # Create a copy of the original Test dataset\n",
    "RfcTest_pred = Taiwan_orig_test.copy(deepcopy=True) # Create a copy of the original Test dataset\n",
    "\n",
    "X_log_test   = scale_orig.transform(LogTest_pred.features)\n",
    "y_log_test   = LogTest_pred.labels\n",
    "\n",
    "X_rfc_test   = scale_orig.transform(RfcTest_pred.features)\n",
    "y_rfc_test   = RfcTest_pred.labels\n",
    "\n",
    "# Update a COPY of the Test dataset labels with the predicted labels.\n",
    "LogTest_pred.scores = BiasedLogModel.predict_proba(X_log_test)[:,pos_log_indx].reshape(-1,1)\n",
    "RfcTest_pred.scores = BiasedRfcModel.predict_proba(X_rfc_test)[:,pos_rfc_indx].reshape(-1,1)\n",
    "# At this point we have copies of the Test dataset, whose labels are modified by \n",
    "# the Logistic Regression and Random Forest classifier predictions respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Before - Logistic Regression - DEFAULT value counts:\n",
      "1.0    2337\n",
      "0.0     663\n",
      "Name: DEFAULT, dtype: int64\n",
      "Test Before - Random Forest       - DEFAULT value counts:\n",
      "1.0    2337\n",
      "0.0     663\n",
      "Name: DEFAULT, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# At this point we have run the Test dataset through both classifiers.\n",
    "# These are the counts of the labels that have been predicted..\n",
    "LogTest_df,d = LogTest_pred.convert_to_dataframe(de_dummy_code=False, sep='=', set_category=False)\n",
    "RfcTest_df,d = RfcTest_pred.convert_to_dataframe(de_dummy_code=False, sep='=', set_category=False)\n",
    "print('Test Before - Logistic Regression - DEFAULT value counts:')\n",
    "print(LogTest_df.DEFAULT.value_counts())\n",
    "print('Test Before - Random Forest       - DEFAULT value counts:')\n",
    "print(RfcTest_df.DEFAULT.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### for the Validation set"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Logistic Regression balanced accuracy (no fairness constraints)           = 0.6990\n",
      "Optimal logistic regression classification threshold (no fairness constraints) = 0.7425\n",
      "\n",
      "Best Random Forest balanced accuracy (no fairness constraints)                 = 0.7224\n",
      "Optimal Random Forest classification threshold (no fairness constraints)       = 0.7722\n"
     ]
    }
   ],
   "source": [
    "# Find the optimal parameters from the Validation set using Logistic Regression trained datasets\n",
    "# Best threshold for classification only (no fairness)\n",
    "num_thresh       = 100\n",
    "ba_log_arr       = np.zeros(num_thresh) # Set up a Balanced Accuraccy array for 100 entries\n",
    "ba_rfc_arr       = np.zeros(num_thresh) # Set up a Balanced Accuraccy array for 100 entries\n",
    "class_log_thresh_arr = np.linspace(0.01, 0.99, num_thresh)\n",
    "class_rfc_thresh_arr = np.linspace(0.01, 0.99, num_thresh)\n",
    "\n",
    "for idx_log, class_log_thresh in enumerate(class_log_thresh_arr):\n",
    "    # For the Logistic Regression Classifier trained model..\n",
    "    fav_log_inds = LogValid_pred.scores > class_log_thresh # If the predicted score > threshold, store in fav_ind \n",
    "    LogValid_pred.labels[fav_log_inds]  = LogValid_pred.favorable_label\n",
    "    LogValid_pred.labels[~fav_log_inds] = LogValid_pred.unfavorable_label\n",
    "    classified_metric_log_valid = ClassificationMetric(Taiwan_orig_valid, LogValid_pred, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups  =privileged_groups)\n",
    "    ba_log_arr[idx_log] = 0.5*(classified_metric_log_valid.true_positive_rate()\\\n",
    "                              +classified_metric_log_valid.true_negative_rate())\n",
    "\n",
    "for idx_rfc, class_rfc_thresh in enumerate(class_rfc_thresh_arr):\n",
    "    # Do the same for the Random Forest Classifier trained model..\n",
    "    fav_rfc_inds = RfcValid_pred.scores > class_rfc_thresh # If the predicted score > threshold, store in fav_ind \n",
    "    RfcValid_pred.labels[fav_rfc_inds]  = RfcValid_pred.favorable_label\n",
    "    RfcValid_pred.labels[~fav_rfc_inds] = RfcValid_pred.unfavorable_label\n",
    "    classified_metric_rfc_valid = ClassificationMetric(Taiwan_orig_valid, RfcValid_pred, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups  =privileged_groups)\n",
    "    ba_rfc_arr[idx_rfc] = 0.5*(classified_metric_rfc_valid.true_positive_rate()\\\n",
    "                              +classified_metric_rfc_valid.true_negative_rate())\n",
    "    \n",
    "# Outside the for loop..\n",
    "best_log_ind          = np.where(ba_log_arr == np.max(ba_log_arr))[0][0]\n",
    "best_log_class_thresh = class_log_thresh_arr[best_log_ind]\n",
    "\n",
    "best_rfc_ind          = np.where(ba_rfc_arr == np.max(ba_rfc_arr))[0][0]\n",
    "best_rfc_class_thresh = class_rfc_thresh_arr[best_rfc_ind]\n",
    "\n",
    "display(Markdown(\"#### for the Validation set\"))\n",
    "print(\"Best Logistic Regression balanced accuracy (no fairness constraints)           = %.4f\" % np.max(ba_log_arr))\n",
    "print(\"Optimal logistic regression classification threshold (no fairness constraints) = %.4f\" % best_log_class_thresh)\n",
    "print('')\n",
    "print(\"Best Random Forest balanced accuracy (no fairness constraints)                 = %.4f\" % np.max(ba_rfc_arr))\n",
    "print(\"Optimal Random Forest classification threshold (no fairness constraints)       = %.4f\" % best_rfc_class_thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate optimal parameters for the ROC method\n",
    "# Create an instance of the ROC classification model\n",
    "ROC_log = RejectOptionClassification(unprivileged_groups= unprivileged_groups, \n",
    "                                 privileged_groups  = privileged_groups, \n",
    "                                 low_class_thresh   = 0.01, \n",
    "                                 high_class_thresh  = 0.99,\n",
    "                                 num_class_thresh   = 100, \n",
    "                                 num_ROC_margin     = 50,\n",
    "                                 metric_name        = metric_name,\n",
    "                                 metric_ub          = metric_ub, \n",
    "                                 metric_lb          = metric_lb)\n",
    "ROC_rfc = RejectOptionClassification(unprivileged_groups= unprivileged_groups, \n",
    "                                 privileged_groups  = privileged_groups, \n",
    "                                 low_class_thresh   = 0.01, \n",
    "                                 high_class_thresh  = 0.99,\n",
    "                                 num_class_thresh   = 100, \n",
    "                                 num_ROC_margin     = 50,\n",
    "                                 metric_name        = metric_name,\n",
    "                                 metric_ub          = metric_ub, \n",
    "                                 metric_lb          = metric_lb)\n",
    "# Train the ROC model on the validation dataset \n",
    "ROC_log = ROC_log.fit(Taiwan_orig_valid, LogValid_pred)\n",
    "ROC_rfc = ROC_rfc.fit(Taiwan_orig_valid, RfcValid_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression classification thresholds - Validation dataset\n",
      "Optimal classification threshold (with fairness constraints) = 0.7128\n",
      "Optimal ROC margin = 0.0000\n",
      "\n",
      "Random Forest classification thresholds - Validation dataset\n",
      "Optimal classification threshold (with fairness constraints) = 0.7722\n",
      "Optimal ROC margin = 0.0000\n"
     ]
    }
   ],
   "source": [
    "print('Logistic Regression classification thresholds - Validation dataset')\n",
    "print(\"Optimal classification threshold (with fairness constraints) = %.4f\" % ROC_log.classification_threshold)\n",
    "print(\"Optimal ROC margin = %.4f\" % ROC_log.ROC_margin)\n",
    "print('')\n",
    "print('Random Forest classification thresholds - Validation dataset')\n",
    "print(\"Optimal classification threshold (with fairness constraints) = %.4f\" % ROC_rfc.classification_threshold)\n",
    "print(\"Optimal ROC margin = %.4f\" % ROC_rfc.ROC_margin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Predictions from the Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Logistic Regression - Validation set"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "##### Raw predictions - No fairness constraints, only maximizing balanced accuracy"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced accuracy = 0.6990\n",
      "Statistical parity difference = 0.0669\n",
      "Disparate impact = 1.0887\n",
      "Average odds difference = 0.0598\n",
      "Equal opportunity difference = 0.0515\n",
      "Theil index = 0.1455\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Random Forest - Validation set"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "##### Raw predictions - No fairness constraints, only maximizing balanced accuracy"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced accuracy = 0.7224\n",
      "Statistical parity difference = 0.0418\n",
      "Disparate impact = 1.0569\n",
      "Average odds difference = 0.0184\n",
      "Equal opportunity difference = 0.0348\n",
      "Theil index = 0.1615\n"
     ]
    }
   ],
   "source": [
    "# Metrics for the test set\n",
    "fav_log_inds = LogValid_pred.scores > best_log_class_thresh\n",
    "LogValid_pred.labels[fav_log_inds]  = LogValid_pred.favorable_label\n",
    "LogValid_pred.labels[~fav_log_inds] = LogValid_pred.unfavorable_label\n",
    "display(Markdown(\"#### Logistic Regression - Validation set\"))\n",
    "display(Markdown(\"##### Raw predictions - No fairness constraints, only maximizing balanced accuracy\"))\n",
    "metric_valid_bef = compute_metrics(Taiwan_orig_valid, LogValid_pred, \n",
    "                                   unprivileged_groups, privileged_groups)\n",
    "\n",
    "fav_rfc_inds = RfcValid_pred.scores > best_rfc_class_thresh\n",
    "RfcValid_pred.labels[fav_rfc_inds]  = RfcValid_pred.favorable_label\n",
    "RfcValid_pred.labels[~fav_rfc_inds] = RfcValid_pred.unfavorable_label\n",
    "display(Markdown(\"#### Random Forest - Validation set\"))\n",
    "display(Markdown(\"##### Raw predictions - No fairness constraints, only maximizing balanced accuracy\"))\n",
    "metric_valid_bef = compute_metrics(Taiwan_orig_valid, RfcValid_pred, \n",
    "                                   unprivileged_groups, privileged_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Logistic Regression - Test set"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "##### Transformed predictions - With fairness constraints"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced accuracy = 0.6889\n",
      "Statistical parity difference = 0.0399\n",
      "Disparate impact = 1.0505\n",
      "Average odds difference = 0.0089\n",
      "Equal opportunity difference = 0.0295\n",
      "Theil index = 0.1213\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Random Forest - Test set"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "##### Transformed predictions - With fairness constraints"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced accuracy = 0.7264\n",
      "Statistical parity difference = 0.0167\n",
      "Disparate impact = 1.0232\n",
      "Average odds difference = -0.0121\n",
      "Equal opportunity difference = -0.0027\n",
      "Theil index = 0.1732\n"
     ]
    }
   ],
   "source": [
    "# Metrics for the transformed test set\n",
    "LogROC_test_pred = ROC_log.predict(LogTest_pred)\n",
    "display(Markdown(\"#### Logistic Regression - Test set\"))\n",
    "display(Markdown(\"##### Transformed predictions - With fairness constraints\"))\n",
    "metric_log_test_aft = compute_metrics(Taiwan_orig_test, LogROC_test_pred, \n",
    "                                  unprivileged_groups, privileged_groups)\n",
    "\n",
    "RfcROC_test_pred = ROC_rfc.predict(RfcTest_pred)\n",
    "display(Markdown(\"#### Random Forest - Test set\"))\n",
    "display(Markdown(\"##### Transformed predictions - With fairness constraints\"))\n",
    "metric_rfc_test_aft = compute_metrics(Taiwan_orig_test, RfcROC_test_pred, \n",
    "                                  unprivileged_groups, privileged_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of instances           : 3000.0\n",
      "Base Rate                     : 0.8116666666666666\n",
      "Consistency                   : [0.784]\n",
      "Disparate Impact              : 1.0504995778533277\n",
      "Mean Difference               : 0.039919055504796686\n",
      "Statistical Parity Difference : 0.039919055504796686\n"
     ]
    }
   ],
   "source": [
    "metric_test_bld = BinaryLabelDatasetMetric(LogROC_test_pred,\n",
    "                                           unprivileged_groups=unprivileged_groups,\n",
    "                                           privileged_groups=privileged_groups)\n",
    "print('Number of instances           :', metric_test_bld.num_instances())\n",
    "print('Base Rate                     :', metric_test_bld.base_rate())\n",
    "print('Consistency                   :', metric_test_bld.consistency())\n",
    "print('Disparate Impact              :', metric_test_bld.disparate_impact())\n",
    "print('Mean Difference               :', metric_test_bld.mean_difference())\n",
    "print('Statistical Parity Difference :', metric_test_bld.statistical_parity_difference()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of instances           : 3000.0\n",
      "Base Rate                     : 0.7283333333333334\n",
      "Consistency                   : [0.7476]\n",
      "Disparate Impact              : 1.023240585950483\n",
      "Mean Difference               : 0.016720677249885796\n",
      "Statistical Parity Difference : 0.016720677249885796\n"
     ]
    }
   ],
   "source": [
    "metric_test_bld = BinaryLabelDatasetMetric(RfcROC_test_pred,\n",
    "                                           unprivileged_groups=unprivileged_groups,\n",
    "                                           privileged_groups=privileged_groups)\n",
    "print('Number of instances           :', metric_test_bld.num_instances())\n",
    "print('Base Rate                     :', metric_test_bld.base_rate())\n",
    "print('Consistency                   :', metric_test_bld.consistency())\n",
    "print('Disparate Impact              :', metric_test_bld.disparate_impact())\n",
    "print('Mean Difference               :', metric_test_bld.mean_difference())\n",
    "print('Statistical Parity Difference :', metric_test_bld.statistical_parity_difference()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test After - Logistic Regression - DEFAULT value counts:\n",
      "1.0    2435\n",
      "0.0     565\n",
      "Name: DEFAULT, dtype: int64\n",
      "Test After - Random Forest      - DEFAULT value counts:\n",
      "1.0    2185\n",
      "0.0     815\n",
      "Name: DEFAULT, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "Taiwan_log_ROC_test_df,d = LogROC_test_pred.convert_to_dataframe(de_dummy_code=False, sep='=', set_category=False)\n",
    "Taiwan_rfc_ROC_test_df,d = RfcROC_test_pred.convert_to_dataframe(de_dummy_code=False, sep='=', set_category=False)\n",
    "print('Test After - Logistic Regression - DEFAULT value counts:')\n",
    "print(Taiwan_log_ROC_test_df.DEFAULT.value_counts())\n",
    "print('Test After - Random Forest      - DEFAULT value counts:')\n",
    "print(Taiwan_rfc_ROC_test_df.DEFAULT.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Logistic Regression - Training set"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "##### Transformed predictions - With fairness constraints"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced accuracy = 1.0000\n",
      "Statistical parity difference = 0.0340\n",
      "Disparate impact = 1.0451\n",
      "Average odds difference = 0.0000\n",
      "Equal opportunity difference = 0.0000\n",
      "Theil index = 0.0000\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Random Forest - Training set"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "##### Transformed predictions - With fairness constraints"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced accuracy = 1.0000\n",
      "Statistical parity difference = 0.0340\n",
      "Disparate impact = 1.0451\n",
      "Average odds difference = 0.0000\n",
      "Equal opportunity difference = 0.0000\n",
      "Theil index = 0.0000\n"
     ]
    }
   ],
   "source": [
    "# Metrics for the transformed train set -  - we expect a perfect score!!!\n",
    "Taiwan_log_ROC_train = ROC_log.predict(LogTrain_pred)\n",
    "display(Markdown(\"#### Logistic Regression - Training set\"))\n",
    "display(Markdown(\"##### Transformed predictions - With fairness constraints\"))\n",
    "metric_log_train = compute_metrics(Taiwan_orig_train, Taiwan_log_ROC_train, \n",
    "                                   unprivileged_groups, privileged_groups)\n",
    "\n",
    "Taiwan_rfc_ROC_train = ROC_rfc.predict(RfcTrain_pred)\n",
    "display(Markdown(\"#### Random Forest - Training set\"))\n",
    "display(Markdown(\"##### Transformed predictions - With fairness constraints\"))\n",
    "metric_rfc_train = compute_metrics(Taiwan_orig_train, Taiwan_rfc_ROC_train, \n",
    "                                  unprivileged_groups, privileged_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Unbiased training dataset - model scores"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unbiased Logistic regression validation accuracy: 0.7760833333333333\n",
      "Unbiased Random Forest       validation accuracy: 0.8096666666666666\n",
      "\n",
      "Unbiased Logistic regression balanced accuracy  : 0.49989264626945784\n",
      "Unbiased Random forest balanced accuracy        : 0.6180156352612024\n"
     ]
    }
   ],
   "source": [
    "# Get model performance for the transformed training dataset\n",
    "#Train Logistic Regression and Random Forest Classifiers on original training data\n",
    "X_log_train           = Taiwan_log_ROC_train.features\n",
    "y_log_train           = Taiwan_log_ROC_train.labels.ravel()\n",
    "X_rfc_train           = Taiwan_rfc_ROC_train.features\n",
    "y_rfc_train           = Taiwan_rfc_ROC_train.labels.ravel()\n",
    "\n",
    "UnbiasedLogModel      = LogisticRegression(random_state=101)\n",
    "UnbiasedRfcModel      = RandomForestClassifier(n_estimators=100,max_depth=4,random_state=101)\n",
    "UnbiasedLogModel.fit(X_log_train, y_log_train)\n",
    "UnbiasedRfcModel.fit(X_rfc_train, y_rfc_train)\n",
    "UnbiasedLogPrediction = UnbiasedLogModel.predict(X_log_train)\n",
    "UnbiasedRfcPrediction = UnbiasedRfcModel.predict(X_rfc_train)\n",
    "\n",
    "# Determine the baseline model accuracy for Logistic Regression and Random Forest Classifiers\n",
    "display(Markdown(\"#### Unbiased training dataset - model scores\"))\n",
    "print('Unbiased Logistic regression validation accuracy:',UnbiasedLogModel.score(X_log_train, y_log_train))\n",
    "print('Unbiased Random Forest       validation accuracy:',UnbiasedRfcModel.score(X_rfc_train, y_rfc_train))\n",
    "print('')\n",
    "print('Unbiased Logistic regression balanced accuracy  :', balanced_accuracy_score(y_log_train, UnbiasedLogPrediction))\n",
    "print('Unbiased Random forest balanced accuracy        :', balanced_accuracy_score(y_rfc_train, UnbiasedRfcPrediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy for predicting the Sensitive Variable before bias transformation:\n",
      "Biased Logistic regression validation accuracy: 0.5065\n",
      "Biased Balanced accuracy\n",
      "Biased Logistic regression balanced accuracy  : 0.5008655556202553\n"
     ]
    }
   ],
   "source": [
    "# Is it possible to predict the Sensitive Variable from the transformed dataset - LOG REG\n",
    "Log_ROC_df, d = Taiwan_log_ROC_train.convert_to_dataframe(de_dummy_code=False, sep='=', set_category=False) \n",
    "\n",
    "X_se_train = Log_ROC_df.drop(protected_attr,axis=1)\n",
    "y_se_train = Log_ROC_df[protected_attr]\n",
    "X_se_test  = Taiwan_test_df.drop(protected_attr,axis=1)\n",
    "y_se_test  = Taiwan_test_df[protected_attr]\n",
    "Se_UnbiasedLogModel = LogisticRegression(random_state=101)\n",
    "Se_UnbiasedLogModel.fit(X_se_train, y_se_train) \n",
    "yseLog_pred =  Se_UnbiasedLogModel.predict(X_se_test)\n",
    "# Now test whether we can predict Gender from the test dataset\n",
    "print('Model Accuracy for predicting the Sensitive Variable before bias transformation:')\n",
    "print(f\"Biased Logistic regression validation accuracy: {Se_UnbiasedLogModel.score(X_se_test, y_se_test)}\")\n",
    "print('Biased Balanced accuracy')\n",
    "print(f\"Biased Logistic regression balanced accuracy  : {balanced_accuracy_score(y_se_test, yseLog_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy for predicting the Sensitive Variable before bias transformation:"
     ]
    }
   ],
   "source": [
    "# Is it possible to predict the Sensitive Variable from the transformed dataset - RFC\n",
    "Rfc_ROC_df, d = Taiwan_rfc_ROC_train.convert_to_dataframe(de_dummy_code=False, sep='=', set_category=False) \n",
    "X_se_train = Rfc_ROC_df.drop(protected_attr,axis=1)\n",
    "y_se_train = Rfc_ROC_df[protected_attr]\n",
    "X_se_test  = Taiwan_test_df.drop(protected_attr,axis=1)\n",
    "y_se_test  = Taiwan_test_df[protected_attr]\n",
    "Se_UnbiasedRfcModel = RandomForestClassifier(n_estimators=100,max_depth=4,random_state=101)\n",
    "Se_UnbiasedRfcModel.fit(X_se_train, y_se_train) \n",
    "yseRfc_pred =  Se_UnbiasedRfcModel.predict(X_se_test)\n",
    "# Now test whether we can predict Gender from the test dataset\n",
    "print('Model Accuracy for predicting the Sensitive Variable before bias transformation:')\n",
    "print(f\"Biased Random Forest       validation accuracy: {Se_UnbiasedRfcModel.score(X_se_test, y_se_test)}\")\n",
    "print('Biased Balanced accuracy')\n",
    "print(f\"Biased Random Forest       balanced accuracy  : {balanced_accuracy_score(y_se_test, yseRfc_pred)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
