{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Data handling/display libraries\n",
    "# Import Data handling/display libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from typing import List, Union, Dict\n",
    "# Warnings will be used to silence various model warnings for tidier output\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_0</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>PAY_5</th>\n",
       "      <th>...</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <th>DEFAULT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23539</th>\n",
       "      <td>200000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>10197</td>\n",
       "      <td>10118</td>\n",
       "      <td>10535</td>\n",
       "      <td>1138</td>\n",
       "      <td>1157</td>\n",
       "      <td>1149</td>\n",
       "      <td>500</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25874</th>\n",
       "      <td>170000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>139143</td>\n",
       "      <td>140987</td>\n",
       "      <td>144187</td>\n",
       "      <td>4800</td>\n",
       "      <td>2000</td>\n",
       "      <td>11000</td>\n",
       "      <td>5500</td>\n",
       "      <td>5500</td>\n",
       "      <td>5400</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5406</th>\n",
       "      <td>50000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>40655</td>\n",
       "      <td>40930</td>\n",
       "      <td>40146</td>\n",
       "      <td>2200</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4735</th>\n",
       "      <td>500000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>37985</td>\n",
       "      <td>33050</td>\n",
       "      <td>22185</td>\n",
       "      <td>35465</td>\n",
       "      <td>75212</td>\n",
       "      <td>38169</td>\n",
       "      <td>33209</td>\n",
       "      <td>22289</td>\n",
       "      <td>22289</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15532</th>\n",
       "      <td>140000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE  PAY_0  PAY_2  PAY_3  PAY_4  \\\n",
       "23539     200000    2          1         1   40      0      0      0      0   \n",
       "25874     170000    2          1         1   35      2      2      2      2   \n",
       "5406       50000    2          1         2   25      0      0      0      0   \n",
       "4735      500000    1          2         1   48     -1     -1     -1     -1   \n",
       "15532     140000    1          1         1   39      1     -2     -2     -2   \n",
       "\n",
       "       PAY_5   ...     BILL_AMT4  BILL_AMT5  BILL_AMT6  PAY_AMT1  PAY_AMT2  \\\n",
       "23539      0   ...         10197      10118      10535      1138      1157   \n",
       "25874      2   ...        139143     140987     144187      4800      2000   \n",
       "5406       0   ...         40655      40930      40146      2200      2000   \n",
       "4735      -1   ...         37985      33050      22185     35465     75212   \n",
       "15532     -2   ...             0          0          0         0         0   \n",
       "\n",
       "       PAY_AMT3  PAY_AMT4  PAY_AMT5  PAY_AMT6  DEFAULT  \n",
       "23539      1149       500      1000      1000        0  \n",
       "25874     11000      5500      5500      5400        1  \n",
       "5406       2000      2000      3000      3000        0  \n",
       "4735      38169     33209     22289     22289        0  \n",
       "15532         0         0         0         0        1  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the Taiwan Credit Card Default training dataset\n",
    "train = pd.read_csv('./input/Taiwan-Credit-Card-Default.csv')\n",
    "\n",
    "# Drop the first row because it is a redundant heading row.\n",
    "train.to_csv('./input/Taiwan-Credit-Card-New.csv', header=False, index=False)\n",
    "# Re-read the dataset with its proper column headers\n",
    "train = pd.read_csv('./input/Taiwan-Credit-Card-New.csv')\n",
    "train.drop([\"ID\"], axis=1, inplace=True)\n",
    "train.rename(columns={'default payment next month':'DEFAULT'}, inplace=True)\n",
    "train.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelectCols(TransformerMixin):\n",
    "    \"\"\"Select columns from a DataFrame.\"\"\"\n",
    "    def __init__(self, cols: List[str]) -> None:\n",
    "        self.cols = cols\n",
    "    def fit(self, x: None) -> \"SelectCols\":\n",
    "        \"\"\"Nothing to do.\"\"\"\n",
    "        return self\n",
    "    def transform(self, x: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Return just selected columns.\"\"\"\n",
    "        return x[self.cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NumericEncoder(TransformerMixin):\n",
    "    \"\"\"Remove invalid values from numerical columns, replace with median.\"\"\"\n",
    "    def fit(self, x: pd.DataFrame) -> \"NumericEncoder\":\n",
    "        \"\"\"Learn median for every column in x.\"\"\"\n",
    "        # Find median for all columns, handling non-NaNs invalid values and NaNs\n",
    "        # Where all values are NaNs (after coercion) the median value will be a NaN.\n",
    "        self.encoders_ = {\n",
    "            c: pd.to_numeric(x[c],\n",
    "                             errors='coerce').median(skipna=True) for c in x}\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, x: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"For each column in x, encode NaN values are learned \n",
    "        median and add a flag column indicating where these \n",
    "        replacements were made\"\"\"\n",
    "\n",
    "        # Create a list of new DataFrames, each with 2 columns\n",
    "        output_dfs = []\n",
    "        for c in x:\n",
    "            new_cols = pd.DataFrame()\n",
    "            # Find invalid values that aren't nans (-inf, inf, string)\n",
    "            invalid_idx = pd.to_numeric(x[c].replace([-np.inf, np.inf],\n",
    "                                                     np.nan),\n",
    "                                        errors='coerce').isnull()\n",
    "\n",
    "            # Copy to new df for this column\n",
    "            new_cols.loc[:, c] = x[c].copy()\n",
    "            # Replace the invalid values with learned median\n",
    "            new_cols.loc[invalid_idx, c] = self.encoders_[c]\n",
    "            # Mark these replacement in a new column called \n",
    "            # \"[column_name]_invalid_flag\"\n",
    "            new_cols.loc[:, f\"{c}_invalid_flag\"] = invalid_idx.astype(np.int8)\n",
    "\n",
    "            output_dfs.append(new_cols)\n",
    "\n",
    "        # Concat list of output_dfs to single df\n",
    "        df = pd.concat(output_dfs,\n",
    "                       axis=1)\n",
    "\n",
    "        # Return wtih an remaining NaNs removed. These might exist if the median\n",
    "        # is a NaN because there was no numeric data in the column at all.\n",
    "        return df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Constructing the pipeline\n",
    "# NumericEncoding fork: Select numeric columns -> numeric encode\n",
    "pp_numeric_cols = Pipeline([('select', SelectCols(cols=['LIMIT_BAL','SEX','EDUCATION','MARRIAGE','AGE',\n",
    "                                                       'PAY_0','PAY_2','PAY_3','PAY_4','PAY_5','PAY_6',\n",
    "                                                       'BILL_AMT1','BILL_AMT2','BILL_AMT3','BILL_AMT4','BILL_AMT5','BILL_AMT6',\n",
    "                                                       'PAY_AMT1','PAY_AMT2','PAY_AMT3','PAY_AMT4','PAY_AMT5','PAY_AMT6','DEFAULT'])),\n",
    "                            ('process', NumericEncoder())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       LIMIT_BAL  LIMIT_BAL_invalid_flag  SEX  SEX_invalid_flag  EDUCATION  \\\n",
      "325     210000.0                       0  1.0                 0        2.0   \n",
      "17351    20000.0                       0  2.0                 0        2.0   \n",
      "16844   240000.0                       0  1.0                 0        1.0   \n",
      "23443   260000.0                       0  2.0                 0        2.0   \n",
      "5140    200000.0                       0  1.0                 0        1.0   \n",
      "\n",
      "       EDUCATION_invalid_flag  MARRIAGE  MARRIAGE_invalid_flag   AGE  \\\n",
      "325                         0       2.0                      0  43.0   \n",
      "17351                       0       1.0                      0  43.0   \n",
      "16844                       0       1.0                      0  36.0   \n",
      "23443                       0       1.0                      0  38.0   \n",
      "5140                        0       1.0                      0  43.0   \n",
      "\n",
      "       AGE_invalid_flag          ...           PAY_AMT3  \\\n",
      "325                   0          ...             3000.0   \n",
      "17351                 0          ...                0.0   \n",
      "16844                 0          ...                0.0   \n",
      "23443                 0          ...             7788.0   \n",
      "5140                  0          ...            10000.0   \n",
      "\n",
      "       PAY_AMT3_invalid_flag  PAY_AMT4  PAY_AMT4_invalid_flag  PAY_AMT5  \\\n",
      "325                        0    5000.0                      0    3000.0   \n",
      "17351                      0    1200.0                      0       0.0   \n",
      "16844                      0       0.0                      0       0.0   \n",
      "23443                      0    6267.0                      0    6513.0   \n",
      "5140                       0    5000.0                      0    4000.0   \n",
      "\n",
      "       PAY_AMT5_invalid_flag  PAY_AMT6  PAY_AMT6_invalid_flag  DEFAULT  \\\n",
      "325                        0    3000.0                      0      0.0   \n",
      "17351                      0    3000.0                      0      1.0   \n",
      "16844                      0       0.0                      0      1.0   \n",
      "23443                      0   10000.0                      0      0.0   \n",
      "5140                       0    4000.0                      0      0.0   \n",
      "\n",
      "       DEFAULT_invalid_flag  \n",
      "325                       0  \n",
      "17351                     0  \n",
      "16844                     0  \n",
      "23443                     0  \n",
      "5140                      0  \n",
      "\n",
      "[5 rows x 48 columns]\n"
     ]
    }
   ],
   "source": [
    "# .fit_transform on the adult dataset\n",
    "#columns = [\"age\",\"workclass\",\"fnlwgt\",\"education\",\"educational-num\",\"marital-status\",\"occupation\",\"relationship\",\n",
    "#           \"race\",\"gender\",\"capital-gain\",\"capital-loss\",\"hours-per-week\",\"native-country\",\"income\"]\n",
    "\n",
    "train_pp = pp_numeric_cols.fit_transform(train)\n",
    "print(train_pp.sample(5))\n",
    "train_pp.to_csv('./input/Taiwan-Credit-Card-New.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
