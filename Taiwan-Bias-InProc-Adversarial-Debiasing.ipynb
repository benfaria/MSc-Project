{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To be run after Taiwan-Data-Prep-Marriage\n",
    "# Import Data handling/display libraries\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy  as np \n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble      import RandomForestClassifier\n",
    "from sklearn.linear_model  import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics       import accuracy_score\n",
    "from sklearn.metrics       import auc, roc_auc_score, roc_curve, classification_report, confusion_matrix\n",
    "from IPython.display       import Markdown, display\n",
    "# Import IBM's AI Fairness tooolbox\n",
    "from aif360.datasets       import BinaryLabelDataset\n",
    "from aif360.metrics        import BinaryLabelDatasetMetric\n",
    "from aif360.metrics        import ClassificationMetric\n",
    "from aif360.metrics.utils  import compute_boolean_conditioning_vector\n",
    "from aif360.algorithms.preprocessing.optim_preproc_helpers.data_preproc_functions import load_preproc_data_adult, load_preproc_data_compas, load_preproc_data_german\n",
    "from aif360.algorithms.inprocessing.adversarial_debiasing import AdversarialDebiasing\n",
    "%matplotlib inline\n",
    "# Warnings will be used to silence various model warnings for tidier output\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Taiwan_df = pd.read_csv('./input/Taiwan-Credit-Card-Cleaned-Marriage.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set privileged / unprivileged / favourable / unfavourable values\n",
    "protected_attr = 'MARRIAGE'\n",
    "priv_grp       = 1\n",
    "unpriv_grp     = 2\n",
    "lab            = 'DEFAULT'\n",
    "fav_label      = 0\n",
    "unfav_label    = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the traoning and test splits\n",
    "X = Taiwan_df.drop(lab,axis=1)\n",
    "y = Taiwan_df[lab]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Binary Label Dataset to use with AIF360 APIs\n",
    "# Favourable Label : DEFAULT = 1 (no default)\n",
    "# Favourable Label : DEFAULT = 0 (Default)\n",
    "Taiwan_bld = BinaryLabelDataset(df=pd.concat((X, y), axis=1),\n",
    "                                  label_names=[lab], protected_attribute_names=[protected_attr],\n",
    "                                  favorable_label=fav_label, unfavorable_label=unfav_label)\n",
    "privileged_groups   = [{protected_attr: priv_grp}]   # Married folk (male or female)\n",
    "unprivileged_groups = [{protected_attr: unpriv_grp}] # Single folk  (male or female)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Taiwan_bld_train, Taiwan_bld_test = Taiwan_bld.split([0.8], shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: Difference in mean outcomes between unprivileged/privileged groups = 0.027419\n",
      "Test set: Difference in mean outcomes between unprivileged/privileged groups = 0.017548\n"
     ]
    }
   ],
   "source": [
    "# Metric for the original dataset\n",
    "Taiwan_metric_train = BinaryLabelDatasetMetric(Taiwan_bld_train, \n",
    "                                               unprivileged_groups=unprivileged_groups,\n",
    "                                               privileged_groups=privileged_groups)\n",
    "#display(Markdown(\"#### Original Taiwan_bld training dataset\"))\n",
    "print(\"Train set: Difference in mean outcomes between unprivileged/privileged groups = %f\" % Taiwan_metric_train.mean_difference())\n",
    "Taiwan_metric_test = BinaryLabelDatasetMetric(Taiwan_bld_test, \n",
    "                                              unprivileged_groups=unprivileged_groups,\n",
    "                                              privileged_groups=privileged_groups)\n",
    "print(\"Test set: Difference in mean outcomes between unprivileged/privileged groups = %f\" % Taiwan_metric_test.mean_difference())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scale the binary labelled datasets\n",
    "min_max_scaler = MinMaxScaler()\n",
    "Taiwan_bld_train.features = min_max_scaler.fit_transform(Taiwan_bld_train.features)\n",
    "Taiwan_bld_test.features  = min_max_scaler.fit_transform(Taiwan_bld_test.features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: Difference in mean outcomes between unprivileged and privileged groups = 0.027419\n",
      "Test set: Difference in mean outcomes between unprivileged and privileged groups = 0.017548\n"
     ]
    }
   ],
   "source": [
    "# Verify that the scaling does not affect the group label statistics\n",
    "Taiwan_bld_metric_scaled_train = BinaryLabelDatasetMetric(Taiwan_bld_train, \n",
    "                          unprivileged_groups=unprivileged_groups,\n",
    "                          privileged_groups=privileged_groups)\n",
    "print(\"Train set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % Taiwan_bld_metric_scaled_train.mean_difference())\n",
    "Taiwan_bld_metric_scaled_test = BinaryLabelDatasetMetric(Taiwan_bld_test, \n",
    "                             unprivileged_groups=unprivileged_groups,\n",
    "                             privileged_groups=privileged_groups)\n",
    "print(\"Test set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % Taiwan_bld_metric_scaled_test.mean_difference())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load post-processing algorithm that equalizes the odds\n",
    "# Learn parameters with debias set to FALSE!\n",
    "sess = tf.Session()\n",
    "biased_model = AdversarialDebiasing(privileged_groups = privileged_groups,\n",
    "                          unprivileged_groups = unprivileged_groups,\n",
    "                          scope_name='plain_classifier',\n",
    "                          debias=False,\n",
    "                          sess=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0813 14:36:29.875608 10032 deprecation_wrapper.py:119] From c:\\users\\befaria\\appdata\\local\\continuum\\miniconda3\\lib\\site-packages\\aif360\\algorithms\\inprocessing\\adversarial_debiasing.py:138: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "W0813 14:36:29.877609 10032 deprecation_wrapper.py:119] From c:\\users\\befaria\\appdata\\local\\continuum\\miniconda3\\lib\\site-packages\\aif360\\algorithms\\inprocessing\\adversarial_debiasing.py:142: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0813 14:36:29.883607 10032 deprecation_wrapper.py:119] From c:\\users\\befaria\\appdata\\local\\continuum\\miniconda3\\lib\\site-packages\\aif360\\algorithms\\inprocessing\\adversarial_debiasing.py:87: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "W0813 14:36:31.277653 10032 lazy_loader.py:50] \n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "W0813 14:36:31.313337 10032 deprecation.py:506] From c:\\users\\befaria\\appdata\\local\\continuum\\miniconda3\\lib\\site-packages\\aif360\\algorithms\\inprocessing\\adversarial_debiasing.py:92: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0813 14:36:31.368331 10032 deprecation.py:323] From c:\\users\\befaria\\appdata\\local\\continuum\\miniconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0813 14:36:31.381340 10032 deprecation_wrapper.py:119] From c:\\users\\befaria\\appdata\\local\\continuum\\miniconda3\\lib\\site-packages\\aif360\\algorithms\\inprocessing\\adversarial_debiasing.py:160: The name tf.train.exponential_decay is deprecated. Please use tf.compat.v1.train.exponential_decay instead.\n",
      "\n",
      "W0813 14:36:31.388335 10032 deprecation_wrapper.py:119] From c:\\users\\befaria\\appdata\\local\\continuum\\miniconda3\\lib\\site-packages\\aif360\\algorithms\\inprocessing\\adversarial_debiasing.py:162: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "W0813 14:36:31.389332 10032 deprecation_wrapper.py:119] From c:\\users\\befaria\\appdata\\local\\continuum\\miniconda3\\lib\\site-packages\\aif360\\algorithms\\inprocessing\\adversarial_debiasing.py:166: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
      "\n",
      "W0813 14:36:31.591898 10032 deprecation_wrapper.py:119] From c:\\users\\befaria\\appdata\\local\\continuum\\miniconda3\\lib\\site-packages\\aif360\\algorithms\\inprocessing\\adversarial_debiasing.py:187: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.718564\n",
      "epoch 1; iter: 0; batch classifier loss: 0.515099\n",
      "epoch 2; iter: 0; batch classifier loss: 0.391685\n",
      "epoch 3; iter: 0; batch classifier loss: 0.435972\n",
      "epoch 4; iter: 0; batch classifier loss: 0.422793\n",
      "epoch 5; iter: 0; batch classifier loss: 0.494179\n",
      "epoch 6; iter: 0; batch classifier loss: 0.499144\n",
      "epoch 7; iter: 0; batch classifier loss: 0.410303\n",
      "epoch 8; iter: 0; batch classifier loss: 0.553528\n",
      "epoch 9; iter: 0; batch classifier loss: 0.384676\n",
      "epoch 10; iter: 0; batch classifier loss: 0.363092\n",
      "epoch 11; iter: 0; batch classifier loss: 0.402084\n",
      "epoch 12; iter: 0; batch classifier loss: 0.459060\n",
      "epoch 13; iter: 0; batch classifier loss: 0.376888\n",
      "epoch 14; iter: 0; batch classifier loss: 0.412601\n",
      "epoch 15; iter: 0; batch classifier loss: 0.479588\n",
      "epoch 16; iter: 0; batch classifier loss: 0.453669\n",
      "epoch 17; iter: 0; batch classifier loss: 0.344656\n",
      "epoch 18; iter: 0; batch classifier loss: 0.534104\n",
      "epoch 19; iter: 0; batch classifier loss: 0.374932\n",
      "epoch 20; iter: 0; batch classifier loss: 0.444281\n",
      "epoch 21; iter: 0; batch classifier loss: 0.408695\n",
      "epoch 22; iter: 0; batch classifier loss: 0.423693\n",
      "epoch 23; iter: 0; batch classifier loss: 0.365317\n",
      "epoch 24; iter: 0; batch classifier loss: 0.338980\n",
      "epoch 25; iter: 0; batch classifier loss: 0.411893\n",
      "epoch 26; iter: 0; batch classifier loss: 0.519509\n",
      "epoch 27; iter: 0; batch classifier loss: 0.465218\n",
      "epoch 28; iter: 0; batch classifier loss: 0.435844\n",
      "epoch 29; iter: 0; batch classifier loss: 0.389374\n",
      "epoch 30; iter: 0; batch classifier loss: 0.407411\n",
      "epoch 31; iter: 0; batch classifier loss: 0.459704\n",
      "epoch 32; iter: 0; batch classifier loss: 0.455199\n",
      "epoch 33; iter: 0; batch classifier loss: 0.395524\n",
      "epoch 34; iter: 0; batch classifier loss: 0.423004\n",
      "epoch 35; iter: 0; batch classifier loss: 0.382367\n",
      "epoch 36; iter: 0; batch classifier loss: 0.417081\n",
      "epoch 37; iter: 0; batch classifier loss: 0.402392\n",
      "epoch 38; iter: 0; batch classifier loss: 0.409615\n",
      "epoch 39; iter: 0; batch classifier loss: 0.454448\n",
      "epoch 40; iter: 0; batch classifier loss: 0.413165\n",
      "epoch 41; iter: 0; batch classifier loss: 0.477192\n",
      "epoch 42; iter: 0; batch classifier loss: 0.369524\n",
      "epoch 43; iter: 0; batch classifier loss: 0.394655\n",
      "epoch 44; iter: 0; batch classifier loss: 0.394861\n",
      "epoch 45; iter: 0; batch classifier loss: 0.315838\n",
      "epoch 46; iter: 0; batch classifier loss: 0.516628\n",
      "epoch 47; iter: 0; batch classifier loss: 0.431694\n",
      "epoch 48; iter: 0; batch classifier loss: 0.443841\n",
      "epoch 49; iter: 0; batch classifier loss: 0.375261\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<aif360.algorithms.inprocessing.adversarial_debiasing.AdversarialDebiasing at 0x215dd3fc6d8>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biased_model.fit(Taiwan_bld_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the plain model to test data\n",
    "Taiwan_biased_train = biased_model.predict(Taiwan_bld_train)\n",
    "Taiwan_biased_test  = biased_model.predict(Taiwan_bld_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Plain model - without debiasing - dataset metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: Difference in mean outcomes between unprivileged and privileged groups = 0.017283\n",
      "Test set: Difference in mean outcomes between unprivileged and privileged groups = 0.022866\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Plain model - without debiasing - classification metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Classification accuracy = 0.784979\n",
      "Test set: Balanced classification accuracy = 0.689399\n",
      "Test set: Disparate impact = 1.029817\n",
      "Test set: Equal opportunity difference = 0.008847\n",
      "Test set: Average odds difference = 0.024816\n",
      "Test set: Theil_index = 0.144883\n"
     ]
    }
   ],
   "source": [
    "# Metrics for the dataset from plain model (without debiasing)\n",
    "display(Markdown(\"#### Plain model - without debiasing - dataset metrics\"))\n",
    "Taiwan_metric_biased_train = BinaryLabelDatasetMetric(Taiwan_biased_train, \n",
    "                             unprivileged_groups=unprivileged_groups,\n",
    "                             privileged_groups=privileged_groups)\n",
    "\n",
    "print(\"Train set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % Taiwan_metric_biased_train.mean_difference())\n",
    "\n",
    "Taiwan_metric_biased_test = BinaryLabelDatasetMetric(Taiwan_biased_test, \n",
    "                            unprivileged_groups=unprivileged_groups,\n",
    "                            privileged_groups=privileged_groups)\n",
    "\n",
    "print(\"Test set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % Taiwan_metric_biased_test.mean_difference())\n",
    "\n",
    "display(Markdown(\"#### Plain model - without debiasing - classification metrics\"))\n",
    "Taiwan_classified_metric_biased_test = ClassificationMetric(Taiwan_bld_test,Taiwan_biased_test,\n",
    "                                       unprivileged_groups=unprivileged_groups,\n",
    "                                       privileged_groups=privileged_groups)\n",
    "print(\"Test set: Classification accuracy = %f\" % Taiwan_classified_metric_biased_test.accuracy())\n",
    "TPR = Taiwan_classified_metric_biased_test.true_positive_rate()\n",
    "TNR = Taiwan_classified_metric_biased_test.true_negative_rate()\n",
    "bal_acc_biased_test = 0.5*(TPR+TNR)\n",
    "print(\"Test set: Balanced classification accuracy = %f\" % bal_acc_biased_test)\n",
    "print(\"Test set: Disparate impact = %f\" % Taiwan_classified_metric_biased_test.disparate_impact())\n",
    "print(\"Test set: Equal opportunity difference = %f\" % Taiwan_classified_metric_biased_test.equal_opportunity_difference())\n",
    "print(\"Test set: Average odds difference = %f\" % Taiwan_classified_metric_biased_test.average_odds_difference())\n",
    "print(\"Test set: Theil_index = %f\" % Taiwan_classified_metric_biased_test.theil_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()\n",
    "tf.reset_default_graph()\n",
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "debiased_model = AdversarialDebiasing(privileged_groups = privileged_groups,\n",
    "                          unprivileged_groups = unprivileged_groups,\n",
    "                          scope_name='plain_classifier',\n",
    "                          debias=True,\n",
    "                          sess=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.674932; batch adversarial loss: 0.203929\n",
      "epoch 1; iter: 0; batch classifier loss: 2.030119; batch adversarial loss: 0.497182\n",
      "epoch 2; iter: 0; batch classifier loss: 2.373574; batch adversarial loss: 0.303297\n",
      "epoch 3; iter: 0; batch classifier loss: 2.393769; batch adversarial loss: 0.137478\n",
      "epoch 4; iter: 0; batch classifier loss: 2.640889; batch adversarial loss: -0.039107\n",
      "epoch 5; iter: 0; batch classifier loss: 2.660581; batch adversarial loss: -0.161785\n",
      "epoch 6; iter: 0; batch classifier loss: 2.620665; batch adversarial loss: -0.200813\n",
      "epoch 7; iter: 0; batch classifier loss: 3.066199; batch adversarial loss: -0.462447\n",
      "epoch 8; iter: 0; batch classifier loss: 3.258683; batch adversarial loss: -0.443979\n",
      "epoch 9; iter: 0; batch classifier loss: 3.977088; batch adversarial loss: -0.718088\n",
      "epoch 10; iter: 0; batch classifier loss: 3.963078; batch adversarial loss: -0.804861\n",
      "epoch 11; iter: 0; batch classifier loss: 3.847316; batch adversarial loss: -0.731571\n",
      "epoch 12; iter: 0; batch classifier loss: 4.051556; batch adversarial loss: -0.877809\n",
      "epoch 13; iter: 0; batch classifier loss: 4.185636; batch adversarial loss: -1.015104\n",
      "epoch 14; iter: 0; batch classifier loss: 3.765147; batch adversarial loss: -0.865971\n",
      "epoch 15; iter: 0; batch classifier loss: 3.970853; batch adversarial loss: -1.064555\n",
      "epoch 16; iter: 0; batch classifier loss: 3.849018; batch adversarial loss: -1.218931\n",
      "epoch 17; iter: 0; batch classifier loss: 3.962665; batch adversarial loss: -1.318068\n",
      "epoch 18; iter: 0; batch classifier loss: 4.120177; batch adversarial loss: -1.438194\n",
      "epoch 19; iter: 0; batch classifier loss: 4.156136; batch adversarial loss: -1.474198\n",
      "epoch 20; iter: 0; batch classifier loss: 3.908625; batch adversarial loss: -1.617530\n",
      "epoch 21; iter: 0; batch classifier loss: 3.859458; batch adversarial loss: -1.719232\n",
      "epoch 22; iter: 0; batch classifier loss: 3.667657; batch adversarial loss: -1.444474\n",
      "epoch 23; iter: 0; batch classifier loss: 3.733673; batch adversarial loss: -1.583161\n",
      "epoch 24; iter: 0; batch classifier loss: 4.005718; batch adversarial loss: -1.917283\n",
      "epoch 25; iter: 0; batch classifier loss: 3.849750; batch adversarial loss: -1.876848\n",
      "epoch 26; iter: 0; batch classifier loss: 3.606308; batch adversarial loss: -1.943813\n",
      "epoch 27; iter: 0; batch classifier loss: 4.262573; batch adversarial loss: -2.100108\n",
      "epoch 28; iter: 0; batch classifier loss: 3.873432; batch adversarial loss: -2.290406\n",
      "epoch 29; iter: 0; batch classifier loss: 3.520360; batch adversarial loss: -2.012471\n",
      "epoch 30; iter: 0; batch classifier loss: 3.607343; batch adversarial loss: -2.170312\n",
      "epoch 31; iter: 0; batch classifier loss: 3.996369; batch adversarial loss: -2.163996\n",
      "epoch 32; iter: 0; batch classifier loss: 4.254204; batch adversarial loss: -2.532001\n",
      "epoch 33; iter: 0; batch classifier loss: 3.622917; batch adversarial loss: -2.316257\n",
      "epoch 34; iter: 0; batch classifier loss: 3.959215; batch adversarial loss: -2.482600\n",
      "epoch 35; iter: 0; batch classifier loss: 3.889612; batch adversarial loss: -2.543002\n",
      "epoch 36; iter: 0; batch classifier loss: 3.896315; batch adversarial loss: -2.715193\n",
      "epoch 37; iter: 0; batch classifier loss: 3.610163; batch adversarial loss: -2.505286\n",
      "epoch 38; iter: 0; batch classifier loss: 3.696828; batch adversarial loss: -2.796697\n",
      "epoch 39; iter: 0; batch classifier loss: 3.624011; batch adversarial loss: -2.612639\n",
      "epoch 40; iter: 0; batch classifier loss: 3.743408; batch adversarial loss: -2.829255\n",
      "epoch 41; iter: 0; batch classifier loss: 3.286717; batch adversarial loss: -2.883846\n",
      "epoch 42; iter: 0; batch classifier loss: 3.287757; batch adversarial loss: -2.554309\n",
      "epoch 43; iter: 0; batch classifier loss: 3.084682; batch adversarial loss: -2.644888\n",
      "epoch 44; iter: 0; batch classifier loss: 3.469715; batch adversarial loss: -3.044308\n",
      "epoch 45; iter: 0; batch classifier loss: 2.733147; batch adversarial loss: -2.692110\n",
      "epoch 46; iter: 0; batch classifier loss: 3.413108; batch adversarial loss: -3.557716\n",
      "epoch 47; iter: 0; batch classifier loss: 2.703912; batch adversarial loss: -2.779533\n",
      "epoch 48; iter: 0; batch classifier loss: 3.060318; batch adversarial loss: -3.104854\n",
      "epoch 49; iter: 0; batch classifier loss: 3.086136; batch adversarial loss: -3.056317\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<aif360.algorithms.inprocessing.adversarial_debiasing.AdversarialDebiasing at 0x215dd3fc898>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "debiased_model.fit(Taiwan_bld_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "Taiwan_debiased_train = debiased_model.predict(Taiwan_bld_train)\n",
    "Taiwan_debiased_test  = debiased_model.predict(Taiwan_bld_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Plain model - after debiasing - dataset metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: Difference in mean outcomes between unprivileged and privileged groups = -0.845176\n",
      "Test set: Difference in mean outcomes between unprivileged and privileged groups = -0.053965\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Plain model - after debiasing - classification metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Classification accuracy = 0.250295\n",
      "Test set: Balanced classification accuracy = 0.509911\n",
      "Test set: Disparate impact = 0.000000\n",
      "Test set: Equal opportunity difference = -0.064672\n",
      "Test set: Average odds difference = -0.042305\n",
      "Test set: Theil_index = 1.379676\n"
     ]
    }
   ],
   "source": [
    "# Metrics for the dataset from plain model (without debiasing)\n",
    "display(Markdown(\"#### Plain model - after debiasing - dataset metrics\"))\n",
    "Taiwan_metric_debiased_train = BinaryLabelDatasetMetric(Taiwan_debiased_train, \n",
    "                               unprivileged_groups=unprivileged_groups,\n",
    "                               privileged_groups=privileged_groups)\n",
    "\n",
    "print(\"Train set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % Taiwan_metric_debiased_train.mean_difference())\n",
    "\n",
    "Taiwan_metric_debiased_test = BinaryLabelDatasetMetric(Taiwan_debiased_test, \n",
    "                              unprivileged_groups=unprivileged_groups,\n",
    "                              privileged_groups=privileged_groups)\n",
    "\n",
    "print(\"Test set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % Taiwan_metric_debiased_test.mean_difference())\n",
    "\n",
    "display(Markdown(\"#### Plain model - after debiasing - classification metrics\"))\n",
    "Taiwan_classified_metric_debiased_test = ClassificationMetric(Taiwan_bld_test,Taiwan_debiased_test,\n",
    "                                         unprivileged_groups=unprivileged_groups,\n",
    "                                         privileged_groups=privileged_groups)\n",
    "print(\"Test set: Classification accuracy = %f\" % Taiwan_classified_metric_debiased_test.accuracy())\n",
    "TPR = Taiwan_classified_metric_debiased_test.true_positive_rate()\n",
    "TNR = Taiwan_classified_metric_debiased_test.true_negative_rate()\n",
    "bal_acc_debiased_test = 0.5*(TPR+TNR)\n",
    "print(\"Test set: Balanced classification accuracy = %f\" % bal_acc_debiased_test)\n",
    "print(\"Test set: Disparate impact = %f\" % Taiwan_classified_metric_debiased_test.disparate_impact())\n",
    "print(\"Test set: Equal opportunity difference = %f\" % Taiwan_classified_metric_debiased_test.equal_opportunity_difference())\n",
    "print(\"Test set: Average odds difference = %f\" % Taiwan_classified_metric_debiased_test.average_odds_difference())\n",
    "print(\"Test set: Theil_index = %f\" % Taiwan_classified_metric_debiased_test.theil_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
