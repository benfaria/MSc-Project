{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To be run after Adult-Data-Prep\n",
    "# Import Data handling/display libraries\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy  as np \n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble      import RandomForestClassifier\n",
    "from sklearn.linear_model  import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics       import accuracy_score\n",
    "from sklearn.metrics       import balanced_accuracy_score\n",
    "from sklearn.metrics       import auc, roc_auc_score, roc_curve, classification_report, confusion_matrix\n",
    "from IPython.display       import Markdown, display\n",
    "# Import IBM's AI Fairness tooolbox\n",
    "from aif360.datasets       import BinaryLabelDataset\n",
    "from aif360.metrics        import BinaryLabelDatasetMetric\n",
    "from aif360.metrics        import ClassificationMetric\n",
    "from aif360.metrics.utils  import compute_boolean_conditioning_vector\n",
    "#from aif360.algorithms.preprocessing.optim_preproc_helpers.data_preproc_functions import load_preproc_data_adult, load_preproc_data_compas, load_preproc_data_Adult\n",
    "from aif360.algorithms.inprocessing.adversarial_debiasing import AdversarialDebiasing\n",
    "%matplotlib inline\n",
    "# Warnings will be used to silence various model warnings for tidier output\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the cleaned Adult dataset\n",
    "Adult_df = pd.read_csv('./input/adult-cleaned.csv')\n",
    "# The AIF demo drops the following columns - we'll try the same\n",
    "Adult_df.drop([\"Fnlwgt\"],axis=1,inplace=True)\n",
    "#Adult_df.drop([\"Fnlwgt\", \"NativeCountry\", \"Relationship\", \"MaritalStatus\"],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set privileged (1)/ unprivileged (0)/ favourable (1) / unfavourable values (0)\n",
    "protected_attr      = 'Gender'\n",
    "priv_grp            = 1  # Males \n",
    "unpriv_grp          = 0  # Females  \n",
    "lab                 = 'Income'\n",
    "fav_label           = 1 # Income over £50K\n",
    "unfav_label         = 0 # Income under £50K\n",
    "privileged_groups   = [{protected_attr: priv_grp}]   # Males\n",
    "unprivileged_groups = [{protected_attr: unpriv_grp}] # Females"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the traoning and test splits\n",
    "X = Adult_df.drop(lab,axis=1)\n",
    "y = Adult_df[lab]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Binary Label Dataset to use with AIF360 APIs\n",
    "Adult_bld = BinaryLabelDataset(df=pd.concat((X, y), axis=1),\n",
    "                                label_names=[lab], protected_attribute_names=[protected_attr],\n",
    "                                favorable_label=fav_label, unfavorable_label=unfav_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train and test datasets\n",
    "Adult_train_bld, Adult_test_bld = Adult_bld.split([0.8], shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scale the binary labelled datasets\n",
    "min_max_scaler = MinMaxScaler()\n",
    "Adult_train_bld.features = min_max_scaler.fit_transform(Adult_train_bld.features)\n",
    "Adult_test_bld.features  = min_max_scaler.fit_transform(Adult_test_bld.features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the train and test datasets to dataframes\n",
    "Adult_train_df, d = Adult_train_bld.convert_to_dataframe(de_dummy_code=False, sep='=', set_category=False)\n",
    "Adult_test_df,  d = Adult_test_bld.convert_to_dataframe(de_dummy_code=False, sep='=', set_category=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Biased Logistic regression validation accuracy: 0.8244446719213839\n",
      "Biased Random Forest       validation accuracy: 0.8384686252431159\n",
      "\n",
      "Biased Logistic regression balanced accuracy  : 0.6875551809078394\n",
      "Biased Random forest balanced accuracy        : 0.6779616210211661\n"
     ]
    }
   ],
   "source": [
    "# Determine the baseline model accuracy for Logistic Regression and Random Forest Classifiers\n",
    "X_train = Adult_train_df.drop(lab,axis=1)\n",
    "y_train = Adult_train_df[lab]\n",
    "X_test  = Adult_test_df.drop(lab,axis=1)\n",
    "y_test  = Adult_test_df[lab]\n",
    "BiasedLogModel = LogisticRegression(random_state=101)\n",
    "BiasedRfcModel = RandomForestClassifier(n_estimators=100,max_depth=4,random_state=101)\n",
    "BiasedLogModel.fit(X_train, y_train) \n",
    "BiasedRfcModel.fit(X_train, y_train)\n",
    "BiasedLogPredictions = BiasedLogModel.predict(X_test)\n",
    "BiasedRfcPredictions = BiasedRfcModel.predict(X_test)\n",
    "print(f\"Biased Logistic regression validation accuracy: {BiasedLogModel.score(X_test, y_test)}\")\n",
    "print(f\"Biased Random Forest       validation accuracy: {BiasedRfcModel.score(X_test, y_test)}\")\n",
    "print('')\n",
    "print(f\"Biased Logistic regression balanced accuracy  : {balanced_accuracy_score(y_test, BiasedLogPredictions)}\")\n",
    "print(f\"Biased Random forest balanced accuracy        : {balanced_accuracy_score(y_test, BiasedRfcPredictions)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Before - Income value counts:\n",
      "0.0    29710\n",
      "1.0     9363\n",
      "Name: Income, dtype: int64\n",
      "Training Before - Gender value counts:\n",
      "1.0    26142\n",
      "0.0    12931\n",
      "Name: Gender, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Training Before - Income value counts:')\n",
    "print(Adult_train_df.Income.value_counts())\n",
    "print('Training Before - Gender value counts:')\n",
    "print(Adult_train_df.Gender.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Before - Income value counts:\n",
      "0.0    7445\n",
      "1.0    2324\n",
      "Name: Income, dtype: int64\n",
      "Test Before - Gender value counts:\n",
      "1.0    6508\n",
      "0.0    3261\n",
      "Name: Gender, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Test Before - Income value counts:')\n",
    "print(Adult_test_df.Income.value_counts())\n",
    "print('Test Before - Gender value counts:')\n",
    "print(Adult_test_df.Gender.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the binary label dataset metric class for the training dataset\n",
    "metric_train_bld = BinaryLabelDatasetMetric(Adult_train_bld, \n",
    "                                            unprivileged_groups=unprivileged_groups,\n",
    "                                            privileged_groups=privileged_groups)\n",
    "metric_test_bld = BinaryLabelDatasetMetric(Adult_test_bld, \n",
    "                                           unprivileged_groups=unprivileged_groups,\n",
    "                                           privileged_groups=privileged_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Orig training dataset"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of instances           : 39073.0\n",
      "Base Rate                     : 0.23962838788933535\n",
      "Consistency                   : [0.8318532]\n",
      "Disparate Impact              : 0.3578237554537522\n",
      "Mean Difference               : -0.19541397082722825\n",
      "Statistical Parity Difference : -0.19541397082722825\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Orig test dataset"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of instances           : 9769.0\n",
      "Base Rate                     : 0.23789538335551233\n",
      "Consistency                   : [0.82456751]\n",
      "Disparate Impact              : 0.36701485922563437\n",
      "Mean Difference               : -0.19092652602029497\n",
      "Statistical Parity Difference : -0.19092652602029497\n"
     ]
    }
   ],
   "source": [
    "display(Markdown(\"#### Orig training dataset\"))\n",
    "print('Number of instances           :', metric_train_bld.num_instances())\n",
    "print('Base Rate                     :', metric_train_bld.base_rate())\n",
    "print('Consistency                   :', metric_train_bld.consistency())\n",
    "print('Disparate Impact              :', metric_train_bld.disparate_impact())\n",
    "print('Mean Difference               :', metric_train_bld.mean_difference())\n",
    "print('Statistical Parity Difference :', metric_train_bld.statistical_parity_difference()) \n",
    "display(Markdown(\"#### Orig test dataset\"))\n",
    "print('Number of instances           :', metric_test_bld.num_instances())\n",
    "print('Base Rate                     :', metric_test_bld.base_rate())\n",
    "print('Consistency                   :', metric_test_bld.consistency())\n",
    "print('Disparate Impact              :', metric_test_bld.disparate_impact())\n",
    "print('Mean Difference               :', metric_test_bld.mean_difference())\n",
    "print('Statistical Parity Difference :', metric_test_bld.statistical_parity_difference()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test for equality of odds. \n",
    "Test_Log_bld = Adult_test_bld.copy(deepcopy=True)\n",
    "Test_Rfc_bld = Adult_test_bld.copy(deepcopy=True)\n",
    "TestLogPredictions = BiasedLogModel.predict(X_test)\n",
    "TestRfcPredictions = BiasedRfcModel.predict(X_test)\n",
    "Test_Log_bld.labels= TestLogPredictions\n",
    "Test_Rfc_bld.labels= TestRfcPredictions\n",
    "\n",
    "c_Log_metric = ClassificationMetric(Adult_test_bld, Test_Log_bld, \n",
    "                                unprivileged_groups=unprivileged_groups,\n",
    "                                privileged_groups=privileged_groups)\n",
    "c_Rfc_metric = ClassificationMetric(Adult_test_bld, Test_Rfc_bld, \n",
    "                                unprivileged_groups=unprivileged_groups,\n",
    "                                privileged_groups=privileged_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A value of 0 means that equality of odds has been met\n",
      "Log average_abs_odds_difference: 0.1788771774875064\n",
      "Log average_odds_difference:     -0.1788771774875064\n",
      " \n",
      "Rfc average_abs_odds_difference: 0.10458697728436953\n",
      "Rfc average_odds_difference:     -0.10458697728436953\n"
     ]
    }
   ],
   "source": [
    "print('A value of 0 means that equality of odds has been met')\n",
    "print('Log average_abs_odds_difference:', c_Log_metric.average_abs_odds_difference())\n",
    "print('Log average_odds_difference:    ', c_Log_metric.average_odds_difference())\n",
    "print(' ')\n",
    "print('Rfc average_abs_odds_difference:', c_Rfc_metric.average_abs_odds_difference())\n",
    "print('Rfc average_odds_difference:    ', c_Rfc_metric.average_odds_difference())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test for Equality of odds\n",
    "Test_bld = BinaryLabelDataset(df=pd.concat((X_test, y_test),axis=1),\n",
    "                              label_names=[lab], protected_attribute_names=[protected_attr],\n",
    "                              favorable_label=fav_label, unfavorable_label=unfav_label)\n",
    "Test_Log_bld = Test_bld.copy(deepcopy=True)\n",
    "Test_Rfc_bld = Test_bld.copy(deepcopy=True)\n",
    "TestLogPredictions = BiasedLogModel.predict(X_test)\n",
    "TestRfcPredictions = BiasedRfcModel.predict(X_test)\n",
    "Test_Log_bld.labels= TestLogPredictions\n",
    "Test_Rfc_bld.labels= TestRfcPredictions#\n",
    "\n",
    "c_Log_metric = ClassificationMetric(Test_bld, Test_Log_bld, \n",
    "                                unprivileged_groups=unprivileged_groups,\n",
    "                                privileged_groups=privileged_groups)\n",
    "c_Rfc_metric = ClassificationMetric(Test_bld, Test_Rfc_bld, \n",
    "                                unprivileged_groups=unprivileged_groups,\n",
    "                                privileged_groups=privileged_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A value of 0 means that equality of odds has been met\n",
      "Log average_abs_odds_difference: 0.1788771774875064\n",
      "Log average_odds_difference:     -0.1788771774875064\n",
      " \n",
      "Rfc average_abs_odds_difference: 0.10458697728436953\n",
      "Rfc average_odds_difference:     -0.10458697728436953\n"
     ]
    }
   ],
   "source": [
    "print('A value of 0 means that equality of odds has been met')\n",
    "print('Log average_abs_odds_difference:', c_Log_metric.average_abs_odds_difference())\n",
    "print('Log average_odds_difference:    ', c_Log_metric.average_odds_difference())\n",
    "print(' ')\n",
    "print('Rfc average_abs_odds_difference:', c_Rfc_metric.average_abs_odds_difference())\n",
    "print('Rfc average_odds_difference:    ', c_Rfc_metric.average_odds_difference())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load post-processing algorithm that equalizes the odds\n",
    "# Learn parameters with debias set to FALSE!\n",
    "sess = tf.Session()\n",
    "biased_model = AdversarialDebiasing(privileged_groups = privileged_groups,\n",
    "                          unprivileged_groups = unprivileged_groups,\n",
    "                          scope_name='plain_classifier',\n",
    "                          debias=False,\n",
    "                          sess=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0910 19:14:44.673133  2100 deprecation_wrapper.py:119] From c:\\users\\befaria\\appdata\\local\\continuum\\miniconda3\\lib\\site-packages\\aif360\\algorithms\\inprocessing\\adversarial_debiasing.py:138: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "W0910 19:14:44.675139  2100 deprecation_wrapper.py:119] From c:\\users\\befaria\\appdata\\local\\continuum\\miniconda3\\lib\\site-packages\\aif360\\algorithms\\inprocessing\\adversarial_debiasing.py:142: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0910 19:14:44.694133  2100 deprecation_wrapper.py:119] From c:\\users\\befaria\\appdata\\local\\continuum\\miniconda3\\lib\\site-packages\\aif360\\algorithms\\inprocessing\\adversarial_debiasing.py:87: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "W0910 19:14:46.732129  2100 lazy_loader.py:50] \n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "W0910 19:14:46.763130  2100 deprecation.py:506] From c:\\users\\befaria\\appdata\\local\\continuum\\miniconda3\\lib\\site-packages\\aif360\\algorithms\\inprocessing\\adversarial_debiasing.py:92: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0910 19:14:46.824139  2100 deprecation.py:323] From c:\\users\\befaria\\appdata\\local\\continuum\\miniconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0910 19:14:46.852129  2100 deprecation_wrapper.py:119] From c:\\users\\befaria\\appdata\\local\\continuum\\miniconda3\\lib\\site-packages\\aif360\\algorithms\\inprocessing\\adversarial_debiasing.py:160: The name tf.train.exponential_decay is deprecated. Please use tf.compat.v1.train.exponential_decay instead.\n",
      "\n",
      "W0910 19:14:46.862128  2100 deprecation_wrapper.py:119] From c:\\users\\befaria\\appdata\\local\\continuum\\miniconda3\\lib\\site-packages\\aif360\\algorithms\\inprocessing\\adversarial_debiasing.py:162: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "W0910 19:14:46.864128  2100 deprecation_wrapper.py:119] From c:\\users\\befaria\\appdata\\local\\continuum\\miniconda3\\lib\\site-packages\\aif360\\algorithms\\inprocessing\\adversarial_debiasing.py:166: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
      "\n",
      "W0910 19:14:47.152129  2100 deprecation_wrapper.py:119] From c:\\users\\befaria\\appdata\\local\\continuum\\miniconda3\\lib\\site-packages\\aif360\\algorithms\\inprocessing\\adversarial_debiasing.py:187: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.725036\n",
      "epoch 0; iter: 200; batch classifier loss: 0.442806\n",
      "epoch 1; iter: 0; batch classifier loss: 0.412049\n",
      "epoch 1; iter: 200; batch classifier loss: 0.410577\n",
      "epoch 2; iter: 0; batch classifier loss: 0.338738\n",
      "epoch 2; iter: 200; batch classifier loss: 0.347446\n",
      "epoch 3; iter: 0; batch classifier loss: 0.339487\n",
      "epoch 3; iter: 200; batch classifier loss: 0.285346\n",
      "epoch 4; iter: 0; batch classifier loss: 0.341591\n",
      "epoch 4; iter: 200; batch classifier loss: 0.331817\n",
      "epoch 5; iter: 0; batch classifier loss: 0.351455\n",
      "epoch 5; iter: 200; batch classifier loss: 0.321800\n",
      "epoch 6; iter: 0; batch classifier loss: 0.288243\n",
      "epoch 6; iter: 200; batch classifier loss: 0.376674\n",
      "epoch 7; iter: 0; batch classifier loss: 0.288993\n",
      "epoch 7; iter: 200; batch classifier loss: 0.340328\n",
      "epoch 8; iter: 0; batch classifier loss: 0.338564\n",
      "epoch 8; iter: 200; batch classifier loss: 0.279655\n",
      "epoch 9; iter: 0; batch classifier loss: 0.333028\n",
      "epoch 9; iter: 200; batch classifier loss: 0.342598\n",
      "epoch 10; iter: 0; batch classifier loss: 0.343790\n",
      "epoch 10; iter: 200; batch classifier loss: 0.288659\n",
      "epoch 11; iter: 0; batch classifier loss: 0.336253\n",
      "epoch 11; iter: 200; batch classifier loss: 0.287240\n",
      "epoch 12; iter: 0; batch classifier loss: 0.364508\n",
      "epoch 12; iter: 200; batch classifier loss: 0.331727\n",
      "epoch 13; iter: 0; batch classifier loss: 0.340417\n",
      "epoch 13; iter: 200; batch classifier loss: 0.344706\n",
      "epoch 14; iter: 0; batch classifier loss: 0.290727\n",
      "epoch 14; iter: 200; batch classifier loss: 0.434248\n",
      "epoch 15; iter: 0; batch classifier loss: 0.344498\n",
      "epoch 15; iter: 200; batch classifier loss: 0.321058\n",
      "epoch 16; iter: 0; batch classifier loss: 0.368874\n",
      "epoch 16; iter: 200; batch classifier loss: 0.295649\n",
      "epoch 17; iter: 0; batch classifier loss: 0.249432\n",
      "epoch 17; iter: 200; batch classifier loss: 0.262579\n",
      "epoch 18; iter: 0; batch classifier loss: 0.398348\n",
      "epoch 18; iter: 200; batch classifier loss: 0.345349\n",
      "epoch 19; iter: 0; batch classifier loss: 0.341096\n",
      "epoch 19; iter: 200; batch classifier loss: 0.329314\n",
      "epoch 20; iter: 0; batch classifier loss: 0.245812\n",
      "epoch 20; iter: 200; batch classifier loss: 0.365201\n",
      "epoch 21; iter: 0; batch classifier loss: 0.347664\n",
      "epoch 21; iter: 200; batch classifier loss: 0.306713\n",
      "epoch 22; iter: 0; batch classifier loss: 0.318362\n",
      "epoch 22; iter: 200; batch classifier loss: 0.301403\n",
      "epoch 23; iter: 0; batch classifier loss: 0.344524\n",
      "epoch 23; iter: 200; batch classifier loss: 0.334618\n",
      "epoch 24; iter: 0; batch classifier loss: 0.400241\n",
      "epoch 24; iter: 200; batch classifier loss: 0.316117\n",
      "epoch 25; iter: 0; batch classifier loss: 0.254847\n",
      "epoch 25; iter: 200; batch classifier loss: 0.332426\n",
      "epoch 26; iter: 0; batch classifier loss: 0.298720\n",
      "epoch 26; iter: 200; batch classifier loss: 0.315626\n",
      "epoch 27; iter: 0; batch classifier loss: 0.318851\n",
      "epoch 27; iter: 200; batch classifier loss: 0.251372\n",
      "epoch 28; iter: 0; batch classifier loss: 0.277165\n",
      "epoch 28; iter: 200; batch classifier loss: 0.348449\n",
      "epoch 29; iter: 0; batch classifier loss: 0.305513\n",
      "epoch 29; iter: 200; batch classifier loss: 0.279010\n",
      "epoch 30; iter: 0; batch classifier loss: 0.290400\n",
      "epoch 30; iter: 200; batch classifier loss: 0.438957\n",
      "epoch 31; iter: 0; batch classifier loss: 0.182307\n",
      "epoch 31; iter: 200; batch classifier loss: 0.279399\n",
      "epoch 32; iter: 0; batch classifier loss: 0.306678\n",
      "epoch 32; iter: 200; batch classifier loss: 0.306852\n",
      "epoch 33; iter: 0; batch classifier loss: 0.289634\n",
      "epoch 33; iter: 200; batch classifier loss: 0.399755\n",
      "epoch 34; iter: 0; batch classifier loss: 0.246874\n",
      "epoch 34; iter: 200; batch classifier loss: 0.290636\n",
      "epoch 35; iter: 0; batch classifier loss: 0.322321\n",
      "epoch 35; iter: 200; batch classifier loss: 0.307847\n",
      "epoch 36; iter: 0; batch classifier loss: 0.340301\n",
      "epoch 36; iter: 200; batch classifier loss: 0.279951\n",
      "epoch 37; iter: 0; batch classifier loss: 0.226858\n",
      "epoch 37; iter: 200; batch classifier loss: 0.332780\n",
      "epoch 38; iter: 0; batch classifier loss: 0.385626\n",
      "epoch 38; iter: 200; batch classifier loss: 0.314250\n",
      "epoch 39; iter: 0; batch classifier loss: 0.298650\n",
      "epoch 39; iter: 200; batch classifier loss: 0.262884\n",
      "epoch 40; iter: 0; batch classifier loss: 0.238980\n",
      "epoch 40; iter: 200; batch classifier loss: 0.235238\n",
      "epoch 41; iter: 0; batch classifier loss: 0.271556\n",
      "epoch 41; iter: 200; batch classifier loss: 0.284515\n",
      "epoch 42; iter: 0; batch classifier loss: 0.291781\n",
      "epoch 42; iter: 200; batch classifier loss: 0.312539\n",
      "epoch 43; iter: 0; batch classifier loss: 0.359221\n",
      "epoch 43; iter: 200; batch classifier loss: 0.330563\n",
      "epoch 44; iter: 0; batch classifier loss: 0.303670\n",
      "epoch 44; iter: 200; batch classifier loss: 0.315066\n",
      "epoch 45; iter: 0; batch classifier loss: 0.317161\n",
      "epoch 45; iter: 200; batch classifier loss: 0.363791\n",
      "epoch 46; iter: 0; batch classifier loss: 0.371112\n",
      "epoch 46; iter: 200; batch classifier loss: 0.330816\n",
      "epoch 47; iter: 0; batch classifier loss: 0.292293\n",
      "epoch 47; iter: 200; batch classifier loss: 0.258992\n",
      "epoch 48; iter: 0; batch classifier loss: 0.379333\n",
      "epoch 48; iter: 200; batch classifier loss: 0.319711\n",
      "epoch 49; iter: 0; batch classifier loss: 0.308465\n",
      "epoch 49; iter: 200; batch classifier loss: 0.364554\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<aif360.algorithms.inprocessing.adversarial_debiasing.AdversarialDebiasing at 0x22d101dfc88>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biased_model.fit(Adult_train_bld)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the plain model to test data\n",
    "Adult_biased_train = biased_model.predict(Adult_train_bld)\n",
    "Adult_biased_test  = biased_model.predict(Adult_test_bld)\n",
    "# And convert them to dataframes\n",
    "Adult_train_df, d = Adult_biased_train.convert_to_dataframe(de_dummy_code=False, sep='=', set_category=False)\n",
    "Adult_test_df, d  = Adult_biased_test.convert_to_dataframe(de_dummy_code=False, sep='=', set_category=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy for predicting the Sensitive Variable before bias transformation:\n",
      "Biased Logistic regression validation accuracy: 0.7525847067253557\n",
      "Biased Random Forest       validation accuracy: 0.7956802129184154\n",
      "\n",
      "Biased Balanced accuracy\n",
      "Biased Logistic regression balanced accuracy  : 0.6892301259394\n",
      "Biased Random Forest       balanced accuracy  : 0.7501854392122205\n"
     ]
    }
   ],
   "source": [
    "# Test whether it is possible to predict the Sensitive Variable from the biased dataset\n",
    "X_se_train = Adult_train_df.drop(protected_attr,axis=1)\n",
    "y_se_train = Adult_train_df[protected_attr]\n",
    "X_se_test  = Adult_test_df.drop(protected_attr,axis=1)\n",
    "y_se_test  = Adult_test_df[protected_attr]\n",
    "\n",
    "Se_BiasedLogModel = LogisticRegression(random_state=101)\n",
    "Se_BiasedRfcModel = RandomForestClassifier(n_estimators=100,max_depth=4,random_state=101)\n",
    "Se_BiasedLogModel.fit(X_se_train, y_se_train) \n",
    "Se_BiasedRfcModel.fit(X_se_train, y_se_train) \n",
    "yseLog_pred =  Se_BiasedLogModel.predict(X_se_test)\n",
    "yseRfc_pred =  Se_BiasedRfcModel.predict(X_se_test)\n",
    "# Now test whether we can predict Gender from the test dataset\n",
    "print('Model Accuracy for predicting the Sensitive Variable before bias transformation:')\n",
    "print(f\"Biased Logistic regression validation accuracy: {Se_BiasedLogModel.score(X_se_test, y_se_test)}\")\n",
    "print(f\"Biased Random Forest       validation accuracy: {Se_BiasedRfcModel.score(X_se_test, y_se_test)}\")\n",
    "print('')\n",
    "print('Biased Balanced accuracy')\n",
    "print(f\"Biased Logistic regression balanced accuracy  : {balanced_accuracy_score(y_se_test, yseLog_pred)}\")\n",
    "print(f\"Biased Random Forest       balanced accuracy  : {balanced_accuracy_score(y_se_test, yseRfc_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Plain model - without debiasing - dataset metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "#### Biased training dataset"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of instances           : 39073.0\n",
      "Base Rate                     : 0.19704143526220153\n",
      "Consistency                   : [0.96067361]\n",
      "Disparate Impact              : 0.2852547840972396\n",
      "Mean Difference               : -0.18446889953698742\n",
      "Statistical Parity Difference : -0.18446889953698742\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Biased test dataset"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of instances           : 9769.0\n",
      "Base Rate                     : 0.19766608660047089\n",
      "Consistency                   : [0.94468216]\n",
      "Disparate Impact              : 0.27652777536697276\n",
      "Mean Difference               : -0.18853855147166781\n",
      "Statistical Parity Difference : -0.18853855147166781\n"
     ]
    }
   ],
   "source": [
    "# Metrics for the dataset from plain model (without debiasing)\n",
    "display(Markdown(\"#### Plain model - without debiasing - dataset metrics\"))\n",
    "metric_biased_train = BinaryLabelDatasetMetric(Adult_biased_train, \n",
    "                             unprivileged_groups=unprivileged_groups,\n",
    "                             privileged_groups=privileged_groups)\n",
    "\n",
    "metric_biased_test = BinaryLabelDatasetMetric(Adult_biased_test, \n",
    "                            unprivileged_groups=unprivileged_groups,\n",
    "                            privileged_groups=privileged_groups)\n",
    "display(Markdown(\"#### Biased training dataset\"))\n",
    "print('Number of instances           :', metric_biased_train.num_instances())\n",
    "print('Base Rate                     :', metric_biased_train.base_rate())\n",
    "print('Consistency                   :', metric_biased_train.consistency())\n",
    "print('Disparate Impact              :', metric_biased_train.disparate_impact())\n",
    "print('Mean Difference               :', metric_biased_train.mean_difference())\n",
    "print('Statistical Parity Difference :', metric_biased_train.statistical_parity_difference()) \n",
    "display(Markdown(\"#### Biased test dataset\"))\n",
    "print('Number of instances           :', metric_biased_test.num_instances())\n",
    "print('Base Rate                     :', metric_biased_test.base_rate())\n",
    "print('Consistency                   :', metric_biased_test.consistency())\n",
    "print('Disparate Impact              :', metric_biased_test.disparate_impact())\n",
    "print('Mean Difference               :', metric_biased_test.mean_difference())\n",
    "print('Statistical Parity Difference :', metric_biased_test.statistical_parity_difference()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Classification metric for train and test\n",
    "classified_metric_biased_test = ClassificationMetric(Adult_train_bld, Adult_biased_train,\n",
    "                                       unprivileged_groups=unprivileged_groups,\n",
    "                                       privileged_groups=privileged_groups)\n",
    "classified_metric_biased_train = ClassificationMetric(Adult_test_bld, Adult_biased_test,\n",
    "                                       unprivileged_groups=unprivileged_groups,\n",
    "                                       privileged_groups=privileged_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Plain model - without debiasing - classification metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "#### Biased training dataset - CLassification Metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy         = 0.8535162247927116\n",
      "Balanced classification accuracy= 0.7689309670804488\n",
      "Disparate impact                = 0.27652777536697276\n",
      "Equal opportunity difference    = -0.15851140842427008\n",
      "Average odds difference         = -0.11827622695406441\n",
      "Theil_index                     = 0.11779794438022112\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Biased test dataset - CLassification Metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy         = 0.8538632815499194\n",
      "Balanced classification accuracy= 0.7690622023790586\n",
      "Disparate impact                = 0.2852547840972396\n",
      "Equal opportunity difference    = -0.10077361650762806\n",
      "Average odds difference         = -0.0904799397691296\n",
      "Theil_index                     = 0.11848825605542657\n"
     ]
    }
   ],
   "source": [
    "display(Markdown(\"#### Plain model - without debiasing - classification metrics\"))\n",
    "\n",
    "display(Markdown(\"#### Biased training dataset - CLassification Metrics\"))\n",
    "TPR_train = classified_metric_biased_train.true_positive_rate()\n",
    "TNR_train = classified_metric_biased_train.true_negative_rate()\n",
    "bal_acc_biased_train = 0.5*(TPR_train + TNR_train)\n",
    "print('Classification accuracy         =', classified_metric_biased_train.accuracy())\n",
    "print('Balanced classification accuracy=', bal_acc_biased_train)\n",
    "print('Disparate impact                =', classified_metric_biased_train.disparate_impact())\n",
    "print('Equal opportunity difference    =', classified_metric_biased_train.equal_opportunity_difference())\n",
    "print('Average odds difference         =', classified_metric_biased_train.average_odds_difference())\n",
    "print('Theil_index                     =', classified_metric_biased_train.theil_index())\n",
    "\n",
    "display(Markdown(\"#### Biased test dataset - CLassification Metrics\"))\n",
    "TPR_test = classified_metric_biased_test.true_positive_rate()\n",
    "TNR_test = classified_metric_biased_test.true_negative_rate()\n",
    "bal_acc_biased_test = 0.5*(TPR_test+TNR_test)\n",
    "print('Classification accuracy         =', classified_metric_biased_test.accuracy())\n",
    "print('Balanced classification accuracy=', bal_acc_biased_test)\n",
    "print('Disparate impact                =', classified_metric_biased_test.disparate_impact())\n",
    "print('Equal opportunity difference    =', classified_metric_biased_test.equal_opportunity_difference())\n",
    "print('Average odds difference         =', classified_metric_biased_test.average_odds_difference())\n",
    "print('Theil_index                     =', classified_metric_biased_test.theil_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()\n",
    "tf.reset_default_graph()\n",
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "unbiased_model = AdversarialDebiasing(privileged_groups = privileged_groups,\n",
    "                          unprivileged_groups = unprivileged_groups,\n",
    "                          scope_name='plain_classifier',\n",
    "                          debias=True,\n",
    "                          sess=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.688806; batch adversarial loss: 0.708610\n",
      "epoch 0; iter: 200; batch classifier loss: 0.549827; batch adversarial loss: 0.675114\n",
      "epoch 1; iter: 0; batch classifier loss: 0.526568; batch adversarial loss: 0.644793\n",
      "epoch 1; iter: 200; batch classifier loss: 0.454933; batch adversarial loss: 0.652382\n",
      "epoch 2; iter: 0; batch classifier loss: 0.485578; batch adversarial loss: 0.667268\n",
      "epoch 2; iter: 200; batch classifier loss: 0.387557; batch adversarial loss: 0.659195\n",
      "epoch 3; iter: 0; batch classifier loss: 0.368546; batch adversarial loss: 0.633070\n",
      "epoch 3; iter: 200; batch classifier loss: 0.370732; batch adversarial loss: 0.641306\n",
      "epoch 4; iter: 0; batch classifier loss: 0.328418; batch adversarial loss: 0.672769\n",
      "epoch 4; iter: 200; batch classifier loss: 0.288229; batch adversarial loss: 0.632936\n",
      "epoch 5; iter: 0; batch classifier loss: 0.375741; batch adversarial loss: 0.585835\n",
      "epoch 5; iter: 200; batch classifier loss: 0.323261; batch adversarial loss: 0.633305\n",
      "epoch 6; iter: 0; batch classifier loss: 0.377932; batch adversarial loss: 0.633307\n",
      "epoch 6; iter: 200; batch classifier loss: 0.386467; batch adversarial loss: 0.613913\n",
      "epoch 7; iter: 0; batch classifier loss: 0.334989; batch adversarial loss: 0.656722\n",
      "epoch 7; iter: 200; batch classifier loss: 0.353932; batch adversarial loss: 0.633473\n",
      "epoch 8; iter: 0; batch classifier loss: 0.458575; batch adversarial loss: 0.583408\n",
      "epoch 8; iter: 200; batch classifier loss: 0.366172; batch adversarial loss: 0.644572\n",
      "epoch 9; iter: 0; batch classifier loss: 0.363274; batch adversarial loss: 0.625816\n",
      "epoch 9; iter: 200; batch classifier loss: 0.297731; batch adversarial loss: 0.596603\n",
      "epoch 10; iter: 0; batch classifier loss: 0.253320; batch adversarial loss: 0.617815\n",
      "epoch 10; iter: 200; batch classifier loss: 0.331837; batch adversarial loss: 0.636508\n",
      "epoch 11; iter: 0; batch classifier loss: 0.353161; batch adversarial loss: 0.657816\n",
      "epoch 11; iter: 200; batch classifier loss: 0.351546; batch adversarial loss: 0.627067\n",
      "epoch 12; iter: 0; batch classifier loss: 0.396322; batch adversarial loss: 0.607792\n",
      "epoch 12; iter: 200; batch classifier loss: 0.329836; batch adversarial loss: 0.655652\n",
      "epoch 13; iter: 0; batch classifier loss: 0.328847; batch adversarial loss: 0.649510\n",
      "epoch 13; iter: 200; batch classifier loss: 0.396040; batch adversarial loss: 0.639314\n",
      "epoch 14; iter: 0; batch classifier loss: 0.316394; batch adversarial loss: 0.632462\n",
      "epoch 14; iter: 200; batch classifier loss: 0.270556; batch adversarial loss: 0.636692\n",
      "epoch 15; iter: 0; batch classifier loss: 0.306382; batch adversarial loss: 0.613224\n",
      "epoch 15; iter: 200; batch classifier loss: 0.425369; batch adversarial loss: 0.590556\n",
      "epoch 16; iter: 0; batch classifier loss: 0.392492; batch adversarial loss: 0.628138\n",
      "epoch 16; iter: 200; batch classifier loss: 0.366566; batch adversarial loss: 0.623257\n",
      "epoch 17; iter: 0; batch classifier loss: 0.309076; batch adversarial loss: 0.631864\n",
      "epoch 17; iter: 200; batch classifier loss: 0.240285; batch adversarial loss: 0.647571\n",
      "epoch 18; iter: 0; batch classifier loss: 0.322519; batch adversarial loss: 0.598538\n",
      "epoch 18; iter: 200; batch classifier loss: 0.288366; batch adversarial loss: 0.612627\n",
      "epoch 19; iter: 0; batch classifier loss: 0.299249; batch adversarial loss: 0.613998\n",
      "epoch 19; iter: 200; batch classifier loss: 0.290913; batch adversarial loss: 0.643853\n",
      "epoch 20; iter: 0; batch classifier loss: 0.295478; batch adversarial loss: 0.575654\n",
      "epoch 20; iter: 200; batch classifier loss: 0.278561; batch adversarial loss: 0.642700\n",
      "epoch 21; iter: 0; batch classifier loss: 0.382029; batch adversarial loss: 0.631185\n",
      "epoch 21; iter: 200; batch classifier loss: 0.298256; batch adversarial loss: 0.666257\n",
      "epoch 22; iter: 0; batch classifier loss: 0.479625; batch adversarial loss: 0.577264\n",
      "epoch 22; iter: 200; batch classifier loss: 0.393669; batch adversarial loss: 0.657087\n",
      "epoch 23; iter: 0; batch classifier loss: 0.280371; batch adversarial loss: 0.648192\n",
      "epoch 23; iter: 200; batch classifier loss: 0.339760; batch adversarial loss: 0.589679\n",
      "epoch 24; iter: 0; batch classifier loss: 0.351279; batch adversarial loss: 0.591164\n",
      "epoch 24; iter: 200; batch classifier loss: 0.355144; batch adversarial loss: 0.619713\n",
      "epoch 25; iter: 0; batch classifier loss: 0.338643; batch adversarial loss: 0.639924\n",
      "epoch 25; iter: 200; batch classifier loss: 0.318309; batch adversarial loss: 0.559709\n",
      "epoch 26; iter: 0; batch classifier loss: 0.262651; batch adversarial loss: 0.623247\n",
      "epoch 26; iter: 200; batch classifier loss: 0.343294; batch adversarial loss: 0.625614\n",
      "epoch 27; iter: 0; batch classifier loss: 0.389867; batch adversarial loss: 0.657077\n",
      "epoch 27; iter: 200; batch classifier loss: 0.261951; batch adversarial loss: 0.630403\n",
      "epoch 28; iter: 0; batch classifier loss: 0.301683; batch adversarial loss: 0.638824\n",
      "epoch 28; iter: 200; batch classifier loss: 0.374474; batch adversarial loss: 0.573766\n",
      "epoch 29; iter: 0; batch classifier loss: 0.466909; batch adversarial loss: 0.591731\n",
      "epoch 29; iter: 200; batch classifier loss: 0.328728; batch adversarial loss: 0.604103\n",
      "epoch 30; iter: 0; batch classifier loss: 0.327378; batch adversarial loss: 0.633042\n",
      "epoch 30; iter: 200; batch classifier loss: 0.314906; batch adversarial loss: 0.608419\n",
      "epoch 31; iter: 0; batch classifier loss: 0.310188; batch adversarial loss: 0.560670\n",
      "epoch 31; iter: 200; batch classifier loss: 0.336287; batch adversarial loss: 0.645893\n",
      "epoch 32; iter: 0; batch classifier loss: 0.257603; batch adversarial loss: 0.605897\n",
      "epoch 32; iter: 200; batch classifier loss: 0.348331; batch adversarial loss: 0.672451\n",
      "epoch 33; iter: 0; batch classifier loss: 0.411421; batch adversarial loss: 0.644975\n",
      "epoch 33; iter: 200; batch classifier loss: 0.248516; batch adversarial loss: 0.591677\n",
      "epoch 34; iter: 0; batch classifier loss: 0.436002; batch adversarial loss: 0.638235\n",
      "epoch 34; iter: 200; batch classifier loss: 0.302004; batch adversarial loss: 0.640665\n",
      "epoch 35; iter: 0; batch classifier loss: 0.396208; batch adversarial loss: 0.605479\n",
      "epoch 35; iter: 200; batch classifier loss: 0.363718; batch adversarial loss: 0.629403\n",
      "epoch 36; iter: 0; batch classifier loss: 0.420827; batch adversarial loss: 0.647441\n",
      "epoch 36; iter: 200; batch classifier loss: 0.393624; batch adversarial loss: 0.618243\n",
      "epoch 37; iter: 0; batch classifier loss: 0.276590; batch adversarial loss: 0.601309\n",
      "epoch 37; iter: 200; batch classifier loss: 0.302585; batch adversarial loss: 0.587842\n",
      "epoch 38; iter: 0; batch classifier loss: 0.310714; batch adversarial loss: 0.586332\n",
      "epoch 38; iter: 200; batch classifier loss: 0.322119; batch adversarial loss: 0.653057\n",
      "epoch 39; iter: 0; batch classifier loss: 0.478864; batch adversarial loss: 0.611851\n",
      "epoch 39; iter: 200; batch classifier loss: 0.373875; batch adversarial loss: 0.627253\n",
      "epoch 40; iter: 0; batch classifier loss: 0.316675; batch adversarial loss: 0.668081\n",
      "epoch 40; iter: 200; batch classifier loss: 0.341065; batch adversarial loss: 0.599547\n",
      "epoch 41; iter: 0; batch classifier loss: 0.310628; batch adversarial loss: 0.586809\n",
      "epoch 41; iter: 200; batch classifier loss: 0.352876; batch adversarial loss: 0.632733\n",
      "epoch 42; iter: 0; batch classifier loss: 0.380543; batch adversarial loss: 0.648787\n",
      "epoch 42; iter: 200; batch classifier loss: 0.325655; batch adversarial loss: 0.647463\n",
      "epoch 43; iter: 0; batch classifier loss: 0.414306; batch adversarial loss: 0.609119\n",
      "epoch 43; iter: 200; batch classifier loss: 0.306568; batch adversarial loss: 0.626506\n",
      "epoch 44; iter: 0; batch classifier loss: 0.350863; batch adversarial loss: 0.628253\n",
      "epoch 44; iter: 200; batch classifier loss: 0.413169; batch adversarial loss: 0.606718\n",
      "epoch 45; iter: 0; batch classifier loss: 0.339956; batch adversarial loss: 0.610800\n",
      "epoch 45; iter: 200; batch classifier loss: 0.492083; batch adversarial loss: 0.693516\n",
      "epoch 46; iter: 0; batch classifier loss: 0.337478; batch adversarial loss: 0.637464\n",
      "epoch 46; iter: 200; batch classifier loss: 0.429899; batch adversarial loss: 0.623476\n",
      "epoch 47; iter: 0; batch classifier loss: 0.380325; batch adversarial loss: 0.600042\n",
      "epoch 47; iter: 200; batch classifier loss: 0.338373; batch adversarial loss: 0.659365\n",
      "epoch 48; iter: 0; batch classifier loss: 0.330502; batch adversarial loss: 0.629685\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 48; iter: 200; batch classifier loss: 0.319905; batch adversarial loss: 0.607919\n",
      "epoch 49; iter: 0; batch classifier loss: 0.349859; batch adversarial loss: 0.629609\n",
      "epoch 49; iter: 200; batch classifier loss: 0.372623; batch adversarial loss: 0.594221\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<aif360.algorithms.inprocessing.adversarial_debiasing.AdversarialDebiasing at 0x22d101dfdd8>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unbiased_model.fit(Adult_train_bld)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "Adult_unbiased_train = unbiased_model.predict(Adult_train_bld)\n",
    "Adult_unbiased_test  = unbiased_model.predict(Adult_test_bld)\n",
    "# And convert these to dataframes..\n",
    "Adult_train_df, d = Adult_unbiased_train.convert_to_dataframe(de_dummy_code=False, sep='=', set_category=False)\n",
    "Adult_test_df, d  = Adult_unbiased_test.convert_to_dataframe(de_dummy_code=False, sep='=', set_category=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Plain model - after unbiasing - dataset metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "#### Biased training dataset"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of instances           : 39073.0\n",
      "Base Rate                     : 0.15596447674864997\n",
      "Consistency                   : [0.95782766]\n",
      "Disparate Impact              : 0.7506138828251397\n",
      "Mean Difference               : -0.04239430436558331\n",
      "Statistical Parity Difference : -0.04239430436558331\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Biased test dataset"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of instances           : 9769.0\n",
      "Base Rate                     : 0.160405363906234\n",
      "Consistency                   : [0.94296243]\n",
      "Disparate Impact              : 0.7212980406355712\n",
      "Mean Difference               : -0.04929101954954787\n",
      "Statistical Parity Difference : -0.04929101954954787\n"
     ]
    }
   ],
   "source": [
    "# Metrics for the dataset from plain model (after unbiasing)\n",
    "display(Markdown(\"#### Plain model - after unbiasing - dataset metrics\"))\n",
    "metric_unbiased_train = BinaryLabelDatasetMetric(Adult_unbiased_train, \n",
    "                             unprivileged_groups=unprivileged_groups,\n",
    "                             privileged_groups=privileged_groups)\n",
    "\n",
    "metric_unbiased_test = BinaryLabelDatasetMetric(Adult_unbiased_test, \n",
    "                            unprivileged_groups=unprivileged_groups,\n",
    "                            privileged_groups=privileged_groups)\n",
    "display(Markdown(\"#### Biased training dataset\"))\n",
    "print('Number of instances           :', metric_unbiased_train.num_instances())\n",
    "print('Base Rate                     :', metric_unbiased_train.base_rate())\n",
    "print('Consistency                   :', metric_unbiased_train.consistency())\n",
    "print('Disparate Impact              :', metric_unbiased_train.disparate_impact())\n",
    "print('Mean Difference               :', metric_unbiased_train.mean_difference())\n",
    "print('Statistical Parity Difference :', metric_unbiased_train.statistical_parity_difference()) \n",
    "display(Markdown(\"#### Biased test dataset\"))\n",
    "print('Number of instances           :', metric_unbiased_test.num_instances())\n",
    "print('Base Rate                     :', metric_unbiased_test.base_rate())\n",
    "print('Consistency                   :', metric_unbiased_test.consistency())\n",
    "print('Disparate Impact              :', metric_unbiased_test.disparate_impact())\n",
    "print('Mean Difference               :', metric_unbiased_test.mean_difference())\n",
    "print('Statistical Parity Difference :', metric_unbiased_test.statistical_parity_difference()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Classification metric for train and test\n",
    "classified_metric_unbiased_train = ClassificationMetric(Adult_train_bld, Adult_unbiased_train,\n",
    "                                       unprivileged_groups=unprivileged_groups,\n",
    "                                       privileged_groups=privileged_groups)\n",
    "classified_metric_unbiased_test = ClassificationMetric(Adult_test_bld, Adult_unbiased_test,\n",
    "                                       unprivileged_groups=unprivileged_groups,\n",
    "                                       privileged_groups=privileged_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Plain model - after debiasing - classification metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "#### Unbiased training dataset - CLassification Metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy         = 0.8418601080029688\n",
      "Balanced classification accuracy= 0.7232437234683395\n",
      "Disparate impact                = 0.7506138828251397\n",
      "Equal opportunity difference    = 0.25027132378149824\n",
      "Average odds difference         = 0.1314215808525129\n",
      "Theil_index                     = 0.14370818831644128\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Unbiased test dataset - CLassification Metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy         = 0.8434844917596479\n",
      "Balanced classification accuracy= 0.7281643411408274\n",
      "Disparate impact                = 0.7212980406355712\n",
      "Equal opportunity difference    = 0.1624950786220989\n",
      "Average odds difference         = 0.09046703022565815\n",
      "Theil_index                     = 0.14003453898232962\n"
     ]
    }
   ],
   "source": [
    "display(Markdown(\"#### Plain model - after debiasing - classification metrics\"))\n",
    "display(Markdown(\"#### Unbiased training dataset - CLassification Metrics\"))\n",
    "TPR_train = classified_metric_unbiased_train.true_positive_rate()\n",
    "TNR_train = classified_metric_unbiased_train.true_negative_rate()\n",
    "bal_acc_unbiased_train = 0.5*(TPR_train + TNR_train)\n",
    "print('Classification accuracy         =', classified_metric_unbiased_train.accuracy())\n",
    "print('Balanced classification accuracy=', bal_acc_unbiased_train)\n",
    "print('Disparate impact                =', classified_metric_unbiased_train.disparate_impact())\n",
    "print('Equal opportunity difference    =', classified_metric_unbiased_train.equal_opportunity_difference())\n",
    "print('Average odds difference         =', classified_metric_unbiased_train.average_odds_difference())\n",
    "print('Theil_index                     =', classified_metric_unbiased_train.theil_index())\n",
    "\n",
    "display(Markdown(\"#### Unbiased test dataset - CLassification Metrics\"))\n",
    "TPR_test = classified_metric_unbiased_test.true_positive_rate()\n",
    "TNR_test = classified_metric_unbiased_test.true_negative_rate()\n",
    "bal_acc_unbiased_test = 0.5*(TPR_test+TNR_test)\n",
    "print('Classification accuracy         =', classified_metric_unbiased_test.accuracy())\n",
    "print('Balanced classification accuracy=', bal_acc_unbiased_test)\n",
    "print('Disparate impact                =', classified_metric_unbiased_test.disparate_impact())\n",
    "print('Equal opportunity difference    =', classified_metric_unbiased_test.equal_opportunity_difference())\n",
    "print('Average odds difference         =', classified_metric_unbiased_test.average_odds_difference())\n",
    "print('Theil_index                     =', classified_metric_unbiased_test.theil_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy for Log Reg and RFC after bias transformation:\n",
      "Biased Logistic regression validation accuracy: 0.9002968574060805\n",
      "Biased Random Forest       validation accuracy: 0.9000921281605078\n",
      "\n",
      "Biased Balanced accuracy\n",
      "Biased Logistic regression balanced accuracy  : 0.7379997983277072\n",
      "Biased Random Forest       balanced accuracy  : 0.694255545248898\n"
     ]
    }
   ],
   "source": [
    "# Determine the after-transformation model accuracy for Logistic Regression and Random Forest Classifiers\n",
    "X_train = Adult_train_df.drop(lab,axis=1)\n",
    "y_train = Adult_train_df[lab]\n",
    "X_test  = Adult_test_df.drop(lab,axis=1)\n",
    "y_test  = Adult_test_df[lab]\n",
    "\n",
    "UnbiasedLogModel = LogisticRegression(random_state=101)\n",
    "UnbiasedRfcModel = RandomForestClassifier(n_estimators=100,max_depth=4,random_state=101)\n",
    "UnbiasedLogModel.fit(X_train, y_train) \n",
    "UnbiasedRfcModel.fit(X_train, y_train) \n",
    "UnbiasedLog_pred = UnbiasedLogModel.predict(X_test)\n",
    "UnbiasedRfc_pred = UnbiasedRfcModel.predict(X_test)\n",
    "\n",
    "# Now get Logistic Regression and Random Forest Clasisfication performancce of unbiased data\n",
    "print('Model Accuracy for Log Reg and RFC after bias transformation:')\n",
    "print(f\"Biased Logistic regression validation accuracy: {UnbiasedLogModel.score(X_test, y_test)}\")\n",
    "print(f\"Biased Random Forest       validation accuracy: {UnbiasedRfcModel.score(X_test, y_test)}\")\n",
    "print('')\n",
    "print('Biased Balanced accuracy')\n",
    "print(f\"Biased Logistic regression balanced accuracy  : {balanced_accuracy_score(y_test, UnbiasedLog_pred)}\")\n",
    "print(f\"Biased Random Forest       balanced accuracy  : {balanced_accuracy_score(y_test, UnbiasedRfc_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test for Equality of odds\n",
    "Test_bld = BinaryLabelDataset(df=pd.concat((X_test, y_test),axis=1),\n",
    "                              label_names=[lab], protected_attribute_names=[protected_attr],\n",
    "                              favorable_label=fav_label, unfavorable_label=unfav_label)\n",
    "Test_Log_bld = Test_bld.copy(deepcopy=True)\n",
    "Test_Rfc_bld = Test_bld.copy(deepcopy=True)\n",
    "TestLogPredictions = UnbiasedLogModel.predict(X_test)\n",
    "TestRfcPredictions = UnbiasedRfcModel.predict(X_test)\n",
    "Test_Log_bld.labels= TestLogPredictions\n",
    "Test_Rfc_bld.labels= TestRfcPredictions#\n",
    "\n",
    "c_Log_metric = ClassificationMetric(Test_bld, Test_Log_bld, \n",
    "                                unprivileged_groups=unprivileged_groups,\n",
    "                                privileged_groups=privileged_groups)\n",
    "c_Rfc_metric = ClassificationMetric(Test_bld, Test_Rfc_bld, \n",
    "                                unprivileged_groups=unprivileged_groups,\n",
    "                                privileged_groups=privileged_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A value of 0 means that equality of odds has been met\n",
      "Log average_abs_odds_difference: 0.04989007365531851\n",
      "Log average_odds_difference:     -0.04989007365531851\n",
      " \n",
      "Rfc average_abs_odds_difference: 0.09027473904298801\n",
      "Rfc average_odds_difference:     -0.09027473904298801\n"
     ]
    }
   ],
   "source": [
    "print('A value of 0 means that equality of odds has been met')\n",
    "print('Log average_abs_odds_difference:', c_Log_metric.average_abs_odds_difference())\n",
    "print('Log average_odds_difference:    ', c_Log_metric.average_odds_difference())\n",
    "print(' ')\n",
    "print('Rfc average_abs_odds_difference:', c_Rfc_metric.average_abs_odds_difference())\n",
    "print('Rfc average_odds_difference:    ', c_Rfc_metric.average_odds_difference())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy for predicting the Sensitive Variable before bias transformation:\n",
      "Biased Logistic regression validation accuracy: 0.7537107175760057\n",
      "Biased Random Forest       validation accuracy: 0.7934281912171154\n",
      "\n",
      "Biased Balanced accuracy\n",
      "Biased Logistic regression balanced accuracy  : 0.6840318438071737\n",
      "Biased Random Forest       balanced accuracy  : 0.7488777052073008\n"
     ]
    }
   ],
   "source": [
    "# Finally test whether it is possible to predict the Sensitive Variable from the transformed dataset\n",
    "X_se_train = Adult_train_df.drop(protected_attr,axis=1)\n",
    "y_se_train = Adult_train_df[protected_attr]\n",
    "X_se_test  = Adult_test_df.drop(protected_attr,axis=1)\n",
    "y_se_test  = Adult_test_df[protected_attr]\n",
    "\n",
    "Se_unbiasedLogModel = LogisticRegression(random_state=101)\n",
    "Se_unbiasedRfcModel = RandomForestClassifier(n_estimators=100,max_depth=4,random_state=101)\n",
    "Se_unbiasedLogModel.fit(X_se_train, y_se_train) \n",
    "Se_unbiasedRfcModel.fit(X_se_train, y_se_train) \n",
    "yseLog_pred =  Se_unbiasedLogModel.predict(X_se_test)\n",
    "yseRfc_pred =  Se_unbiasedRfcModel.predict(X_se_test)\n",
    "# Now test whether we can predict Gender from the test dataset\n",
    "print('Model Accuracy for predicting the Sensitive Variable before bias transformation:')\n",
    "print(f\"Biased Logistic regression validation accuracy: {Se_unbiasedLogModel.score(X_se_test, y_se_test)}\")\n",
    "print(f\"Biased Random Forest       validation accuracy: {Se_unbiasedRfcModel.score(X_se_test, y_se_test)}\")\n",
    "print('')\n",
    "print('Biased Balanced accuracy')\n",
    "print(f\"Biased Logistic regression balanced accuracy  : {balanced_accuracy_score(y_se_test, yseLog_pred)}\")\n",
    "print(f\"Biased Random Forest       balanced accuracy  : {balanced_accuracy_score(y_se_test, yseRfc_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Training After - Income value counts:\n",
      "0.0    32979\n",
      "1.0     6094\n",
      "Name: Income, dtype: int64\n",
      "Predicted Training After - Gender value counts:\n",
      "1.0    26142\n",
      "0.0    12931\n",
      "Name: Gender, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Predicted Training After - Income value counts:')\n",
    "print(Adult_train_df.Income.value_counts())\n",
    "print('Predicted Training After - Gender value counts:')\n",
    "print(Adult_train_df.Gender.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Test After - Income value counts:\n",
      "0.0    8202\n",
      "1.0    1567\n",
      "Name: Income, dtype: int64\n",
      "Predicted Test After - Gender value counts:\n",
      "1.0    6508\n",
      "0.0    3261\n",
      "Name: Gender, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Predicted Test After - Income value counts:')\n",
    "print(Adult_test_df.Income.value_counts())\n",
    "print('Predicted Test After - Gender value counts:')\n",
    "print(Adult_test_df.Gender.value_counts())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
