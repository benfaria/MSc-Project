{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This data prep script \n",
    "# Make 0 = unfav/unprivi and 1 fav/priv\n",
    "# Import Data handling/display libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn               as sns\n",
    "import matplotlib.pyplot     as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble        import RandomForestClassifier\n",
    "from sklearn.linear_model    import LogisticRegression\n",
    "from sklearn.preprocessing   import MinMaxScaler, StandardScaler\n",
    "from sklearn.base            import TransformerMixin\n",
    "from sklearn.pipeline        import Pipeline, FeatureUnion\n",
    "from typing                  import List, Union, Dict\n",
    "# Warnings will be used to silence various model warnings for tidier output\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Adult training dataset\n",
    "Adult_df = pd.read_csv('./input/adult.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the data\n",
    "# Replace '?' in relevant columns with the most frequent value in the column \n",
    "attrib, counts = np.unique(Adult_df['Employment'], return_counts = True)\n",
    "most_freq_attrib = attrib[np.argmax(counts, axis=0)]\n",
    "Adult_df['Employment'].replace(' ?',most_freq_attrib,inplace=True)\n",
    "\n",
    "attrib, counts = np.unique(Adult_df['Occupation'], return_counts = True)\n",
    "most_freq_attrib = attrib[np.argmax(counts, axis = 0)]\n",
    "#Adult_df['Occupation'].replace('?',most_freq_attrib,inplace=True)\n",
    "Adult_df['Occupation'].replace('?',most_freq_attrib,inplace=True)\n",
    "\n",
    "attrib, counts = np.unique(Adult_df['NativeCountry'], return_counts = True)\n",
    "most_freq_attrib = attrib[np.argmax(counts, axis = 0)]\n",
    "Adult_df['NativeCountry'].replace('?',most_freq_attrib,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adult values counts 0    37155\n",
      "1    11687\n",
      "Name: Income, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "Adult_df['Income'].replace('>50K' ,1, inplace=True)\n",
    "Adult_df['Income'].replace('<=50K',0, inplace=True)\n",
    "print('Adult values counts',Adult_df.Income.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    32650\n",
      "0    16192\n",
      "Name: Gender, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Make Gender binary values : Male 1, Female 0\n",
    "gender = {'Male': 1,'Female': 0} \n",
    "Adult_df.Gender = [gender[item] for item in Adult_df.Gender]\n",
    "print(Adult_df.Gender.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Income</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gender</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14423</td>\n",
       "      <td>1769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22732</td>\n",
       "      <td>9918</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Income      0     1\n",
       "Gender             \n",
       "0       14423  1769\n",
       "1       22732  9918"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### get into the meat of whats what\n",
    "gender = Adult_df.groupby(['Gender', 'Income']).size().unstack(1)\n",
    "gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x289cb6049b0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot chart of number of women who're high earners etc.\n",
    "gender.plot(kind='bar', stacked = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Males   : 32650\n",
      "Total Females : 16192\n",
      "Percentate of males : 66.84820441423365\n",
      "Ratio Males-Females : 2.0164278656126484\n",
      "\n",
      "Total of high earning males  : 9918\n",
      "Total of high earning females: 1769\n",
      "Percentate of high earning males : 84.863523573201\n",
      "Ratio of high erners: male to female  5.60655737704918\n",
      "\n",
      "Total of low earning males  : 22732\n",
      "Total of low earning females: 14423\n",
      "Percentate of low earning males : 61.1815368052752\n",
      "Ratio of low erners: male to female  1.576093739166609\n"
     ]
    }
   ],
   "source": [
    "Ratio_Males_Females = Ratio_HighIncome_male_female = 0\n",
    "TotalMales          = len(Adult_df[Adult_df[\"Gender\"]==1])\n",
    "TotalFemales        = len(Adult_df[Adult_df[\"Gender\"]==0])\n",
    "Ratio_Males_Females = TotalMales / TotalFemales\n",
    "\n",
    "MaleHighEarners     = len(Adult_df[(Adult_df[\"Gender\"]==1)  & (Adult_df[\"Income\"]==1)])\n",
    "FemaleHighEarners   = len(Adult_df[(Adult_df[\"Gender\"]==0)  & (Adult_df[\"Income\"]==1)])\n",
    "Ratio_HighIncome_male_female = MaleHighEarners / FemaleHighEarners\n",
    "\n",
    "MaleLowEarners     = len(Adult_df[(Adult_df[\"Gender\"]==1)  & (Adult_df[\"Income\"]==0)])\n",
    "FemaleLowEarners   = len(Adult_df[(Adult_df[\"Gender\"]==0)  & (Adult_df[\"Income\"]==0)])\n",
    "Ratio_LowIncome_male_female = MaleLowEarners / FemaleLowEarners\n",
    "\n",
    "\n",
    "print('Total Males   :', TotalMales)\n",
    "print('Total Females :', TotalFemales)\n",
    "print('Percentate of males :',((100*TotalMales) /(TotalMales+TotalFemales)))\n",
    "print('Ratio Males-Females :', Ratio_Males_Females)\n",
    "print('')\n",
    "print('Total of high earning males  :', MaleHighEarners)\n",
    "print('Total of high earning females:', FemaleHighEarners)\n",
    "print('Percentate of high earning males :',((100*MaleHighEarners) /(MaleHighEarners+FemaleHighEarners)))\n",
    "print('Ratio of high erners: male to female ', Ratio_HighIncome_male_female)\n",
    "print('')\n",
    "print('Total of low earning males  :', MaleLowEarners)\n",
    "print('Total of low earning females:', FemaleLowEarners)\n",
    "print('Percentate of low earning males :',((100*MaleLowEarners) /(MaleLowEarners+FemaleLowEarners)))\n",
    "print('Ratio of low erners: male to female ', Ratio_LowIncome_male_female)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelectCols(TransformerMixin):\n",
    "    \"\"\"Select columns from a DataFrame.\"\"\"\n",
    "    def __init__(self, cols: List[str]) -> None:\n",
    "        self.cols = cols\n",
    "    def fit(self, x: None) -> \"SelectCols\":\n",
    "        \"\"\"Nothing to do.\"\"\"\n",
    "        return self\n",
    "    def transform(self, x: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Return just selected columns.\"\"\"\n",
    "        return x[self.cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabelEncoder(TransformerMixin):\n",
    "    # Convert non-numeric columns to numeric using label encoding. \n",
    "    def fit(self, x: pd.DataFrame) -> \"LabelEncoder\":\n",
    "        # Generate encoders for each column.\n",
    "        encoders = {}\n",
    "        for c in x:\n",
    "            # Generate encoders using pd.factorize on unique values, then convert to a dictionary\n",
    "            v, k = zip(pd.factorize(x[c].unique()))\n",
    "            encoders[c] = dict(zip(k[0], v[0]))\n",
    "        self.encoders_ = encoders\n",
    "        return self\n",
    "\n",
    "    def transform(self, x) -> pd.DataFrame:\n",
    "        # For columns in x that have learned encoders, apply encoding.\n",
    "        x = x.copy()\n",
    "        for c in x:\n",
    "            # Ignore new, unseen values\n",
    "            x.loc[~x[c].isin(self.encoders_[c]), c] = np.nan\n",
    "            # Map learned labels\n",
    "            x.loc[:, c] = x[c].map(self.encoders_[c])\n",
    "        # Return without nans\n",
    "        return x.fillna(-2).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NumericEncoder(TransformerMixin):\n",
    "    \"\"\"Remove invalid values from numerical columns, replace with median.\"\"\"\n",
    "    def fit(self, x: pd.DataFrame) -> \"NumericEncoder\":\n",
    "        \"\"\"Learn median for every column in x.\"\"\"\n",
    "        # Find median for all columns, handling non-NaNs invalid values and NaNs\n",
    "        # Where all values are NaNs (after coercion) the median value will be a NaN.\n",
    "        self.encoders_ = {\n",
    "            c: pd.to_numeric(x[c], errors='coerce').median(skipna=True) for c in x}\n",
    "        return self\n",
    "\n",
    "    def transform(self, x: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"For each column in x, encode NaN values are learned \n",
    "        median and add a flag column indicating where these \n",
    "        replacements were made\"\"\"\n",
    "\n",
    "        # Create a list of new DataFrames, each with 2 columns\n",
    "        output_dfs = []\n",
    "        for c in x:\n",
    "            new_cols = pd.DataFrame()\n",
    "            # Find invalid values that aren't nans (-inf, inf, string)\n",
    "            invalid_idx = pd.to_numeric(x[c].replace([-np.inf, np.inf], np.nan),\n",
    "                                        errors='coerce').isnull()\n",
    "            # Copy to new df for this column\n",
    "            new_cols.loc[:, c] = x[c].copy()\n",
    "            # Replace the invalid values with learned median\n",
    "            new_cols.loc[invalid_idx, c] = self.encoders_[c]\n",
    "            # Mark these replacement in a new column called \n",
    "            # \"[column_name]_invalid_flag\"\n",
    "            # new_cols.loc[:, f\"{c}_invalid_flag\"] = invalid_idx.astype(np.int8)\n",
    "\n",
    "            output_dfs.append(new_cols)\n",
    "\n",
    "        # Concat list of output_dfs to single df\n",
    "        df = pd.concat(output_dfs,\n",
    "                       axis=1)\n",
    "\n",
    "        # Return wtih an remaining NaNs removed. These might exist if the median\n",
    "        # is a NaN because there was no numeric data in the column at all.\n",
    "        return df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Constructing the feature engineering pipeline\n",
    "# LabelEncoding fork: Select object columns -> label encode\n",
    "pp_object_cols = Pipeline([('select', SelectCols(cols=['Employment', 'Education', \n",
    "                                                       'MaritalStatus', 'Occupation', \n",
    "                                                       'Relationship','Race','NativeCountry'])),\n",
    "                           ('process', LabelEncoder())])\n",
    "\n",
    "# NumericEncoding fork: Select numeric columns -> numeric encode\n",
    "pp_numeric_cols = Pipeline([('select', SelectCols(cols=['Age','Fnlwgt','EducationNum','CapitalLoss', \n",
    "                                                        'CapitalGain','HoursPerWeek', 'Gender','Income'])),\n",
    "                            ('process', NumericEncoder())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .fit_transform on the adult dataset and write out to new csv file for bias measurement\n",
    "all_columns = [\"Age\",\"Employment\",\"Fnlwgt\",\"Education\",\"EducationalNum\",\"MaritalStatus\",\"Occupation\",\"Relationship\",\n",
    "           \"Race\",\"Gender\",\"CapitalGain\",\"CapitalLoss\",\"HoursPerWeek\",\"NativeCountry\",\"Income\"]\n",
    "\n",
    "train_pp = pd.concat((pp_numeric_cols.fit_transform(Adult_df), \n",
    "                      pp_object_cols.fit_transform(Adult_df)),\n",
    "                      axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all label encoded columns from from int64 to float64\n",
    "train_pp[[\"Employment\",\"Education\", \"MaritalStatus\",\"Occupation\",\"Relationship\",\"Race\", \n",
    "          \"NativeCountry\"]] = train_pp[[\"Employment\",\"Education\",\"MaritalStatus\",\"Occupation\",\n",
    "                                        \"Relationship\",\"Race\",\n",
    "                                        \"NativeCountry\"]].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorder the columns to have Income the last column - for aesthetics\n",
    "columnsTitles = ['Age','Employment','Fnlwgt','Education','EducationNum','MaritalStatus',\n",
    "                 'Occupation','Relationship','Race','Gender','CapitalGain','CapitalLoss',\n",
    "                 'HoursPerWeek','NativeCountry', 'Income']\n",
    "train_pp = train_pp.reindex(columns=columnsTitles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pp.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender = train_pp.groupby(['Gender', 'Income']).size().unstack(1)\n",
    "gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pp.to_csv('./input/adult-cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## NOW DETERMINE THE MOST IMPORTANT FEATURES OF A LOGISTIC REGRESSION & RANDOM FOREST CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Adult_df = pd.read_csv('./input/adult-cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The AIF demo drops the following columns - we'll try the same\n",
    "Adult_df.drop([\"Fnlwgt\", \"NativeCountry\", \"Relationship\", \"MaritalStatus\"],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up train and test samples.\n",
    "X = Adult_df.drop(\"Income\",axis=1)\n",
    "y = Adult_df[\"Income\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the Test and Train dataframes \n",
    "scaler  = MinMaxScaler(copy=False)\n",
    "X_train = pd.DataFrame(scaler.fit_transform(X_train.values), columns=X_train.columns, index=X_train.index)\n",
    "X_test  = pd.DataFrame(scaler.fit_transform(X_test.values),  columns=X_test.columns,  index=X_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biasedlogmodel = LogisticRegression(random_state=101)\n",
    "biasedlogmodel.fit(X_train,y_train)\n",
    "logpredictions = biasedlogmodel.predict(X_test)\n",
    "print(f\"Logistic regression validation accuracy: {biasedlogmodel.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CODE TO DISPLAY LOG REGRESSION FEATURE IMPORTANCE \n",
    "# List feature importances from the Logistic Regression Classifier\n",
    "log_feature_importance = pd.DataFrame((biasedlogmodel.coef_[0]),index = X_train.columns,\n",
    "                         columns=['importance']).sort_values('importance',ascending=False)\n",
    "log_feature_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CODE TO DISPLAY LOG FEATURE IMPORTANCE\n",
    "# Display feature importances from the Logistic Regression Classifier\n",
    "%matplotlib inline\n",
    "feature_names = list(Adult_df.columns)\n",
    "\n",
    "importances = biasedlogmodel.coef_[0]\n",
    "# Sort feature importances in descending order\n",
    "indices = np.argsort(importances)[::-1]\n",
    " \n",
    "# Rearrange feature names so they match the sorted feature importances\n",
    "names = [feature_names[i] for i in indices]\n",
    "\n",
    "# Barplot: Add bars\n",
    "plt.bar(range(X_train.shape[1]), importances[indices])\n",
    "# Add feature names as x-axis labels\n",
    "plt.xticks(range(X_train.shape[1]), names, rotation=20, fontsize = 8)\n",
    "# Create plot title\n",
    "plt.title(\"Biased Logistic Regression Feature Importance\")\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biasedrfcmodel = RandomForestClassifier(n_estimators=100,max_depth=4)\n",
    "biasedrfcmodel.fit(X_train, y_train)\n",
    "rfcpredictions = biasedrfcmodel.predict(X_test)\n",
    "print(f\"Random forest validation accuracy: {biasedrfcmodel.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## THIS IS MY CODE TO DISPLAY FEATURE IMPORTANCE\n",
    "# List feature importances from the Random Forest Classifier\n",
    "feature_importances = pd.DataFrame(biasedrfcmodel.feature_importances_, index = X_train.columns,\n",
    "                                   columns=['importance']).sort_values('importance',ascending=False)\n",
    "feature_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## THIS IS MY CODE TO DISPLAY FEATURE IMPORTANCE\n",
    "# Display feature importances from the Random Forest Classifier\n",
    "%matplotlib inline\n",
    "feature_names = list(Adult_df.columns)\n",
    "\n",
    "importances = biasedrfcmodel.feature_importances_\n",
    "# Sort feature importances in descending order\n",
    "indices = np.argsort(importances)[::-1]\n",
    " \n",
    "# Rearrange feature names so they match the sorted feature importances\n",
    "names = [feature_names[i] for i in indices]\n",
    "\n",
    "# Barplot: Add bars\n",
    "plt.bar(range(X_train.shape[1]), importances[indices])\n",
    "# Add feature names as x-axis labels\n",
    "plt.xticks(range(X_train.shape[1]), names, rotation=20, fontsize = 8)\n",
    "# Create plot title\n",
    "plt.title(\"Biased RFC Feature Importance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for the attribute with the most impact on a random forest classification\n",
    "%matplotlib inline\n",
    "def feature_importance(mod: Union[LogisticRegression,RandomForestClassifier],\n",
    "                       names: List[str],\n",
    "                       scale=None) -> pd.DataFrame:\n",
    "    \"\"\"Return feature importance for LR or RFC models in a sorted DataFrame.\"\"\"\n",
    "    if type(mod) == LogisticRegression:\n",
    "        imp = np.abs(mod.coef_.squeeze()) / scale\n",
    "        var = np.zeros(shape=imp.shape)\n",
    "    elif type(mod) == RandomForestClassifier:\n",
    "        imps = np.array([fi.feature_importances_ for fi in mod.estimators_])\n",
    "        imp = imps.mean(axis=0)\n",
    "        var = imps.std(axis=0)\n",
    "\n",
    "    return pd.DataFrame({'feature': names,'importance': imp,\n",
    "                         'std': var}).sort_values('importance',ascending=False)\n",
    "def plot_feature_importance(**kwargs) -> None:\n",
    "    ax = sns.barplot(**kwargs)\n",
    "    for l in ax.get_xticklabels():\n",
    "        l.set_rotation(90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(16, 6))\n",
    "plot_feature_importance(x='feature',y='importance', \n",
    "                        data=feature_importance(biasedlogmodel,\n",
    "                                                names=X_train.columns.tolist(),\n",
    "                                                scale=X_train.std()),\n",
    "                       ax=ax[0])\n",
    "_ = ax[0].set_title('LR Feature Importance - before Mitigating')\n",
    "plot_feature_importance(x='feature',y='importance', \n",
    "                        data=feature_importance(biasedrfcmodel,names=X_train.columns.tolist()),\n",
    "                       ax=ax[1])\n",
    "_ = ax[1].set_title('RFC Feature Importance - before Mitigating')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
