{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# Load all necessary packages\n",
    "import sys\n",
    "import pandas  as pd\n",
    "import numpy   as np\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "sns.set_context(\"talk\")\n",
    "import matplotlib.pyplot as plt\n",
    "# Import IBM's AI Fairness tooolbox\n",
    "from aif360.datasets         import BinaryLabelDataset\n",
    "from aif360.metrics          import BinaryLabelDatasetMetric\n",
    "from aif360.metrics          import ClassificationMetric\n",
    "from aif360.metrics.utils    import compute_boolean_conditioning_vector\n",
    "from aif360.algorithms.preprocessing.lfr import LFR\n",
    "# Import scikit-learn core slibraries\n",
    "from sklearn.metrics         import auc, roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import train_test_split  \n",
    "from sklearn.ensemble        import RandomForestClassifier\n",
    "from sklearn.linear_model    import LogisticRegression\n",
    "from sklearn.metrics         import balanced_accuracy_score\n",
    "from sklearn.preprocessing   import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics         import accuracy_score\n",
    "from IPython.display         import Markdown, display\n",
    "from typing                  import List, Union, Dict\n",
    "# Warnings will be used to silence various model warnings for tidier output\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the cleaned Adult dataset\n",
    "Adult_df = pd.read_csv('./input/adult-cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The AIF demo drops the following columns - we'll try the same\n",
    "#Adult_df.drop([\"Fnlwgt\", \"NativeCountry\", \"Relationship\", \"MaritalStatus\"],axis=1,inplace=True)\n",
    "Adult_df.drop([\"Fnlwgt\"],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set privileged (1)/ unprivileged (0)/ favourable (1) / unfavourable values (0)\n",
    "protected_attr      = 'Gender'\n",
    "priv_grp            = 1  # Males \n",
    "unpriv_grp          = 0  # Females  \n",
    "lab                 = 'Income'\n",
    "fav_label           = 1 # Income over £50K\n",
    "unfav_label         = 0 # Income under £50K\n",
    "privileged_groups   = [{protected_attr: priv_grp}]   # Males\n",
    "unprivileged_groups = [{protected_attr: unpriv_grp}] # Females"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Binary Label Dataset to use with AIF360 APIs\n",
    "X = Adult_df.drop(lab,axis=1)\n",
    "y = Adult_df[lab]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Adult_bld = BinaryLabelDataset(df=pd.concat((X, y), axis=1),\n",
    "                                label_names=[lab], protected_attribute_names=[protected_attr],\n",
    "                                favorable_label=fav_label, unfavorable_label=unfav_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train and test datasets\n",
    "Adult_train_bld, Adult_test_bld = Adult_bld.split([0.8], shuffle=True, seed=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(copy=False)\n",
    "Adult_train_bld.features = scaler.fit_transform(Adult_train_bld.features)\n",
    "Adult_test_bld.features  = scaler.fit_transform(Adult_test_bld.features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Adult_train_df, d = Adult_train_bld.convert_to_dataframe(de_dummy_code=False, sep='=', set_category=False)\n",
    "Adult_test_df,  d = Adult_test_bld.convert_to_dataframe(de_dummy_code=False, sep='=', set_category=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy for predicting the Sensitive Variable before bias transformation:\n",
      "Biased Logistic regression validation accuracy: 0.7607738765482649\n",
      "Biased Random Forest       validation accuracy: 0.8003889855665882\n",
      "\n",
      "Biased Balanced accuracy\n",
      "Biased Logistic regression balanced accuracy  : 0.6952920907607211\n",
      "Biased Random Forest       balanced accuracy  : 0.7569811626718649\n"
     ]
    }
   ],
   "source": [
    "# First test whether it is possible to predict the Sensitive Variable from the whole original dataset\n",
    "X_se_train = Adult_train_df.drop(protected_attr,axis=1)\n",
    "y_se_train = Adult_train_df[protected_attr]\n",
    "X_se_test  = Adult_test_df.drop(protected_attr,axis=1)\n",
    "y_se_test  = Adult_test_df[protected_attr]\n",
    "\n",
    "Se_BiasedLogModel = LogisticRegression(random_state=101)\n",
    "Se_BiasedRfcModel = RandomForestClassifier(n_estimators=100,max_depth=4,random_state=101)\n",
    "Se_BiasedLogModel.fit(X_se_train, y_se_train) \n",
    "Se_BiasedRfcModel.fit(X_se_train, y_se_train) \n",
    "yseLog_pred =  Se_BiasedLogModel.predict(X_se_test)\n",
    "yseRfc_pred =  Se_BiasedRfcModel.predict(X_se_test)\n",
    "# Now test whether we can predict Gender from the test dataset\n",
    "print('Model Accuracy for predicting the Sensitive Variable before bias transformation:')\n",
    "print(f\"Biased Logistic regression validation accuracy: {Se_BiasedLogModel.score(X_se_test, y_se_test)}\")\n",
    "print(f\"Biased Random Forest       validation accuracy: {Se_BiasedRfcModel.score(X_se_test, y_se_test)}\")\n",
    "print('')\n",
    "print('Biased Balanced accuracy')\n",
    "print(f\"Biased Logistic regression balanced accuracy  : {balanced_accuracy_score(y_se_test, yseLog_pred)}\")\n",
    "print(f\"Biased Random Forest       balanced accuracy  : {balanced_accuracy_score(y_se_test, yseRfc_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train ds Before - Income value counts:\n",
      "0.0    29750\n",
      "1.0     9323\n",
      "Name: Income, dtype: int64\n",
      "Train ds Before - Gender value counts:\n",
      "1.0    26143\n",
      "0.0    12930\n",
      "Name: Gender, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Next get the number of labels from the training dataset\n",
    "print('Train ds Before - Income value counts:')\n",
    "print(Adult_train_df.Income.value_counts())\n",
    "print('Train ds Before - Gender value counts:')\n",
    "print(Adult_train_df.Gender.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Biased Logistic regression validation accuracy: 0.8195311700276384\n",
      "Biased Random Forest       validation accuracy: 0.8344764049544477\n",
      "\n",
      "Biased Logistic regression balanced accuracy  : 0.6914758971792736\n",
      "Biased Random forest balanced accuracy        : 0.6781526807126022\n"
     ]
    }
   ],
   "source": [
    "# Determine the baseline model accuracy for Logistic Regression and Random Forest Classifiers\n",
    "#Adult_train, d = Adult_train_df.convert_to_dataframe(de_dummy_code=False, sep='=', set_category=False)\n",
    "#Adult_test,  d = Adult_test_df.convert_to_dataframe(de_dummy_code=False, sep='=', set_category=False)\n",
    "X_train = Adult_train_df.drop(lab,axis=1)\n",
    "y_train = Adult_train_df[lab]\n",
    "X_test  = Adult_test_df.drop(lab,axis=1)\n",
    "y_test  = Adult_test_df[lab]\n",
    "BiasedLogModel = LogisticRegression(random_state=101)\n",
    "BiasedRfcModel = RandomForestClassifier(n_estimators=100,max_depth=4,random_state=101)\n",
    "BiasedLogModel.fit(X_train, y_train) \n",
    "BiasedRfcModel.fit(X_train, y_train)\n",
    "BiasedLogPredictions = BiasedLogModel.predict(X_test)\n",
    "BiasedRfcPredictions = BiasedRfcModel.predict(X_test)\n",
    "\n",
    "\n",
    "print(f\"Biased Logistic regression validation accuracy: {BiasedLogModel.score(X_test, y_test)}\")\n",
    "print(f\"Biased Random Forest       validation accuracy: {BiasedRfcModel.score(X_test, y_test)}\")\n",
    "print('')\n",
    "print(f\"Biased Logistic regression balanced accuracy  : {balanced_accuracy_score(y_test, BiasedLogPredictions)}\")\n",
    "print(f\"Biased Random forest balanced accuracy        : {balanced_accuracy_score(y_test, BiasedRfcPredictions)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test for equality of odds. \n",
    "Test_Log_bld = Adult_test_bld.copy(deepcopy=True)\n",
    "Test_Rfc_bld = Adult_test_bld.copy(deepcopy=True)\n",
    "TestLogPredictions = BiasedLogModel.predict(X_test)\n",
    "TestRfcPredictions = BiasedRfcModel.predict(X_test)\n",
    "Test_Log_bld.labels= TestLogPredictions\n",
    "Test_Rfc_bld.labels= TestRfcPredictions\n",
    "\n",
    "c_Log_metric = ClassificationMetric(Adult_test_bld, Test_Log_bld, \n",
    "                                unprivileged_groups=unprivileged_groups,\n",
    "                                privileged_groups=privileged_groups)\n",
    "c_Rfc_metric = ClassificationMetric(Adult_test_bld, Test_Rfc_bld, \n",
    "                                unprivileged_groups=unprivileged_groups,\n",
    "                                privileged_groups=privileged_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A value of 0 means that equality of odds has been met\n",
      "Log average_abs_odds_difference: 0.17240932599510445\n",
      "Log average_odds_difference:     -0.17240932599510445\n",
      " \n",
      "Rfc average_abs_odds_difference: 0.10648112965040518\n",
      "Rfc average_odds_difference:     -0.10648112965040518\n"
     ]
    }
   ],
   "source": [
    "print('A value of 0 means that equality of odds has been met')\n",
    "print('Log average_abs_odds_difference:', c_Log_metric.average_abs_odds_difference())\n",
    "print('Log average_odds_difference:    ', c_Log_metric.average_odds_difference())\n",
    "print(' ')\n",
    "print('Rfc average_abs_odds_difference:', c_Rfc_metric.average_abs_odds_difference())\n",
    "print('Rfc average_odds_difference:    ', c_Rfc_metric.average_odds_difference())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Biased training dataset"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of instances           : 39073.0\n",
      "Base Rate                     :0.238605\n",
      "Consistency                   : [0.83263123]\n",
      "Disparate Impact              : 0.3620832314871518\n",
      "Mean Difference               : -0.19293913814906824\n",
      "Statistical Parity Difference : -0.19293913814906824\n",
      "# of positives(privileged)    : 7907.0\n",
      "# of positives(non-privileged): 1416.0\n",
      "Total positive instances\"     : 9323.0\n",
      "# of negatives(privileged)    : 18236.0\n",
      "# of negatives(non-privileged): 11514.0\n",
      "Total negative instances\"     : 29750.0\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Biased training dataset"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference in mean outcomes between unprivileged and privileged groups = -0.192939\n"
     ]
    }
   ],
   "source": [
    "# Create the binary label dataset metric class for the training dataset\n",
    "metric_train_bld = BinaryLabelDatasetMetric(Adult_train_bld, \n",
    "                                            unprivileged_groups=unprivileged_groups,\n",
    "                                            privileged_groups=privileged_groups)\n",
    "display(Markdown(\"#### Biased training dataset\"))\n",
    "print('Number of instances           :', metric_train_bld.num_instances())\n",
    "print(\"Base Rate                     :%f\" % metric_train_bld.base_rate())\n",
    "print('Consistency                   :', metric_train_bld.consistency())\n",
    "print('Disparate Impact              :', metric_train_bld.disparate_impact())\n",
    "print('Mean Difference               :', metric_train_bld.mean_difference())\n",
    "print('Statistical Parity Difference :', metric_train_bld.statistical_parity_difference()) \n",
    "print('# of positives(privileged)    :', metric_train_bld.num_positives(privileged=True))\n",
    "print('# of positives(non-privileged):', metric_train_bld.num_positives(privileged=False))\n",
    "print('Total positive instances\"     :', metric_train_bld.num_positives(privileged=True)+metric_train_bld.num_positives(privileged=False))\n",
    "print('# of negatives(privileged)    :', metric_train_bld.num_negatives(privileged=True))\n",
    "print('# of negatives(non-privileged):', metric_train_bld.num_negatives(privileged=False))\n",
    "print('Total negative instances\"     :', metric_train_bld.num_negatives(privileged=True)+metric_train_bld.num_negatives(privileged=False))\n",
    "display(Markdown(\"#### Biased training dataset\"))\n",
    "print(\"Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_train_bld.mean_difference())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interval : Optimization objective value for the interval\n",
      "250 21849.304262405436\n",
      "500 21186.80799027204\n",
      "750 21054.782510903264\n",
      "1000 20731.27355023851\n",
      "1250 20550.19550639173\n",
      "1500 20272.674031275958\n",
      "1750 20120.28067033731\n",
      "2000 19974.152501767796\n",
      "2250 19643.61615476599\n",
      "2500 19261.746064233088\n",
      "2750 18583.12398143145\n",
      "3000 31976.33285234392\n",
      "3250 17324.385232441797\n",
      "3500 16990.71487231314\n",
      "3750 16732.202376687987\n",
      "4000 16571.817875708737\n",
      "4250 16453.15483567401\n",
      "4500 16183.432041033486\n",
      "4750 16129.397964549864\n",
      "5000 15842.891201732013\n"
     ]
    }
   ],
   "source": [
    "# Fit the Learning Fair Representations on the biased training data\n",
    "print('Interval : Optimization objective value for the interval')\n",
    "TR = LFR(unprivileged_groups = unprivileged_groups, privileged_groups = privileged_groups,verbose=1, seed=101)\n",
    "TR = TR.fit(Adult_train_bld)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform training data and align features\n",
    "Adult_train_lfr = TR.transform(Adult_train_bld)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Transformed training dataset"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification threshold = 0.100000\n",
      "Consistency                   : [0.99248074]\n",
      "Disparate Impact              : 0.46714881224619065\n",
      "Mean Difference               : -0.4476129340267532\n",
      "\n",
      "Classification threshold = 0.200000\n",
      "Consistency                   : [0.99318199]\n",
      "Disparate Impact              : 0.3189532117367169\n",
      "Mean Difference               : -0.4270512182993535\n",
      "\n",
      "Classification threshold = 0.300000\n",
      "Consistency                   : [0.9945026]\n",
      "Disparate Impact              : 0.22746678527865372\n",
      "Mean Difference               : -0.33279535876493904\n",
      "\n",
      "Classification threshold = 0.400000\n",
      "Consistency                   : [0.99607402]\n",
      "Disparate Impact              : 0.1772203326714131\n",
      "Mean Difference               : -0.24236798447375768\n",
      "\n",
      "Classification threshold = 0.500000\n",
      "Consistency                   : [0.99761472]\n",
      "Disparate Impact              : 0.11361043740213958\n",
      "Mean Difference               : -0.18102107159507236\n",
      "\n",
      "Classification threshold = 0.600000\n",
      "Consistency                   : [0.99834157]\n",
      "Disparate Impact              : 0.07668807122872057\n",
      "Mean Difference               : -0.11732556429553571\n",
      "\n",
      "Classification threshold = 0.700000\n",
      "Consistency                   : [0.99906329]\n",
      "Disparate Impact              : 0.05393228885476937\n",
      "Mean Difference               : -0.06376358134253515\n",
      "\n",
      "Classification threshold = 0.800000\n",
      "Consistency                   : [0.99945743]\n",
      "Disparate Impact              : 0.06836029153680366\n",
      "Mean Difference               : -0.027404312275109893\n",
      "\n",
      "Classification threshold = 0.900000\n",
      "Consistency                   : [0.99972871]\n",
      "Disparate Impact              : 0.11987472831818641\n",
      "Mean Difference               : -0.008517449938243462\n",
      "\n"
     ]
    }
   ],
   "source": [
    "display(Markdown(\"#### Transformed training dataset\"))\n",
    "from sklearn.metrics import classification_report\n",
    "thresholds = np.linspace(0.1, 0.9, 9)\n",
    "for threshold in thresholds:\n",
    "    \n",
    "    # Transform training data and align features\n",
    "    Adult_train_lfr = TR.transform(Adult_train_bld,threshold=threshold)\n",
    "    metric_train_lfr = BinaryLabelDatasetMetric(Adult_train_lfr, \n",
    "                                                 unprivileged_groups=unprivileged_groups,\n",
    "                                                 privileged_groups=privileged_groups)\n",
    "    print(\"Classification threshold = %f\" % threshold)\n",
    "    print('Consistency                   :', metric_train_lfr.consistency())\n",
    "    print('Disparate Impact              :', metric_train_lfr.disparate_impact())\n",
    "    print('Mean Difference               :', metric_train_lfr.mean_difference())\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.9 # Chosen because the disparate impact is closest to 1.\n",
    "Adult_train_lfr = TR.transform(Adult_train_bld,threshold=threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_train_lfr = BinaryLabelDatasetMetric(Adult_train_lfr, \n",
    "                                                 unprivileged_groups=unprivileged_groups,\n",
    "                                                 privileged_groups=privileged_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference in mean outcomes between unprivileged and privileged groups = -0.008517\n",
      "Number of instances           : 39073.0\n",
      "Base Rate                     :0.006859\n",
      "Consistency                   : [0.99972871]\n",
      "Disparate Impact              : 0.11987472831818641\n",
      "Mean Difference               : -0.008517449938243462\n",
      "Statistical Parity Difference : -0.008517449938243462\n",
      "# of positives(privileged)    : 253.0\n",
      "# of positives(non-privileged): 15.0\n",
      "Total positive instances\"     : 268.0\n",
      "# of negatives(privileged)    : 25890.0\n",
      "# of negatives(non-privileged): 12915.0\n",
      "Total negative instances\"     : 38805.0\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Original training dataset"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference in mean outcomes between unprivileged and privileged groups = -0.192939\n"
     ]
    }
   ],
   "source": [
    "print(\"Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_train_lfr.mean_difference())\n",
    "print('Number of instances           :', metric_train_lfr.num_instances())\n",
    "print(\"Base Rate                     :%f\" % metric_train_lfr.base_rate())\n",
    "print('Consistency                   :', metric_train_lfr.consistency())\n",
    "print('Disparate Impact              :', metric_train_lfr.disparate_impact())\n",
    "print('Mean Difference               :', metric_train_lfr.mean_difference())\n",
    "print('Statistical Parity Difference :', metric_train_lfr.statistical_parity_difference()) \n",
    "print('# of positives(privileged)    :', metric_train_lfr.num_positives(privileged=True))\n",
    "print('# of positives(non-privileged):', metric_train_lfr.num_positives(privileged=False))\n",
    "print('Total positive instances\"     :', metric_train_lfr.num_positives(privileged=True)+metric_train_lfr.num_positives(privileged=False))\n",
    "print('# of negatives(privileged)    :', metric_train_lfr.num_negatives(privileged=True))\n",
    "print('# of negatives(non-privileged):', metric_train_lfr.num_negatives(privileged=False))\n",
    "print('Total negative instances\"     :', metric_train_lfr.num_negatives(privileged=True)+metric_train_lfr.num_negatives(privileged=False))\n",
    "display(Markdown(\"#### Original training dataset\"))\n",
    "print(\"Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_train_bld.mean_difference())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the transformed Binary Labelled Datasets to a pandas dataframe for consistency \n",
    "Adult_train_lfr_df, d = Adult_train_lfr.convert_to_dataframe(de_dummy_code=False, sep='=', set_category=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unbiased Logistic regression validation accuracy: 0.7582147609786057\n",
      "Unbiased Random Forest       validation accuracy: 0.7581123963558194\n",
      "\n",
      "UnBiased Logistic regression balanced accuracy  : 0.5004230118443317\n",
      "Unbiased Random Forest       balanced accuracy  : 0.5002115059221658\n"
     ]
    }
   ],
   "source": [
    "# Determine the transformed model accuracy for Logistic Regression and Random Forest Classifiers\n",
    "X_lfr_train = Adult_train_lfr_df.drop(lab,axis=1)\n",
    "y_lfr_train = Adult_train_lfr_df[lab]\n",
    "X_lfr_test  = Adult_test_df.drop(lab,axis=1)\n",
    "y_lfr_test  = Adult_test_df[lab]\n",
    "\n",
    "UnbiasedLogModel = LogisticRegression(random_state=101)\n",
    "UnbiasedRfcModel = RandomForestClassifier(n_estimators=100,max_depth=4,random_state=101)\n",
    "UnbiasedLogModel.fit(X_lfr_train, y_lfr_train) \n",
    "UnbiasedRfcModel.fit(X_lfr_train, y_lfr_train) \n",
    "UnbiasedLogPredictions = UnbiasedLogModel.predict(X_lfr_test)\n",
    "UnbiasedRfcPredictions = UnbiasedRfcModel.predict(X_lfr_test)\n",
    "\n",
    "print(f\"Unbiased Logistic regression validation accuracy: {UnbiasedLogModel.score(X_lfr_test, y_lfr_test)}\")\n",
    "print(f\"Unbiased Random Forest       validation accuracy: {UnbiasedRfcModel.score(X_lfr_test, y_lfr_test)}\")\n",
    "print('')\n",
    "print(f\"UnBiased Logistic regression balanced accuracy  : {balanced_accuracy_score(y_lfr_test, UnbiasedLogPredictions)}\")\n",
    "print(f\"Unbiased Random Forest       balanced accuracy  : {balanced_accuracy_score(y_lfr_test, UnbiasedRfcPredictions)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test for equality of odds. \n",
    "Test_Log_bld = Adult_test_bld.copy(deepcopy=True)\n",
    "Test_Rfc_bld = Adult_test_bld.copy(deepcopy=True)\n",
    "TestLogPredictions = UnbiasedLogModel.predict(X_test)\n",
    "TestRfcPredictions = UnbiasedRfcModel.predict(X_test)\n",
    "Test_Log_bld.labels= TestLogPredictions\n",
    "Test_Rfc_bld.labels= TestRfcPredictions\n",
    "\n",
    "c_Log_metric = ClassificationMetric(Adult_test_bld, Test_Log_bld, \n",
    "                                unprivileged_groups=unprivileged_groups,\n",
    "                                privileged_groups=privileged_groups)\n",
    "c_Rfc_metric = ClassificationMetric(Adult_test_bld, Test_Rfc_bld, \n",
    "                                unprivileged_groups=unprivileged_groups,\n",
    "                                privileged_groups=privileged_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A value of 0 means that equality of odds has been met\n",
      "Log average_abs_odds_difference: 0.0028328611898017\n",
      "Log average_odds_difference:     0.0028328611898017\n",
      " \n",
      "Rfc average_abs_odds_difference: 0.00141643059490085\n",
      "Rfc average_odds_difference:     0.00141643059490085\n"
     ]
    }
   ],
   "source": [
    "print('A value of 0 means that equality of odds has been met')\n",
    "print('Log average_abs_odds_difference:', c_Log_metric.average_abs_odds_difference())\n",
    "print('Log average_odds_difference:    ', c_Log_metric.average_odds_difference())\n",
    "print(' ')\n",
    "print('Rfc average_abs_odds_difference:', c_Rfc_metric.average_abs_odds_difference())\n",
    "print('Rfc average_odds_difference:    ', c_Rfc_metric.average_odds_difference())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "def plot_auc(y_true: np.ndarray, preds: Dict[str, np.ndarray], title: str='', ax=None) -> None:\n",
    "    leg = []\n",
    "    for k, p in preds.items():\n",
    "        fpr, tpr, _ = roc_curve(y_true, p)\n",
    "        ax = sns.lineplot(x=fpr, y=tpr, ci=None, ax=ax)\n",
    "        leg.append(f\"{k}: {round(auc(fpr, tpr), 2)}\")\n",
    "   \n",
    "    ax.legend(leg)\n",
    "    ax.set_xlabel('FPR')\n",
    "    ax.set_ylabel('TPR')\n",
    "    sns.lineplot(x=[0, 1], y=[0, 1], color='gray',ax=ax)\n",
    "    ax.set_title(title)\n",
    "    \n",
    "print('Accuracy:')\n",
    "display(pd.DataFrame({'LogReg': [BiasedLogModel.score(X_test, y_test), \n",
    "                                 UnbiasedLogModel.score(X_lfr_test, y_lfr_test)],\n",
    "                      'RFC': [BiasedRfcModel.score(X_test, y_test),\n",
    "                              UnbiasedRfcModel.score(X_lfr_test, y_lfr_test)]}, \n",
    "                      index =['Biased', 'Fair']))\n",
    "\n",
    "print('AUC:')\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2,figsize=(16, 6))\n",
    "plot_auc(y_test, \n",
    "         {'AUC biased': BiasedLogModel.predict_proba(X_test)[:, 1],\n",
    "          'AUC fair': UnbiasedLogModel.predict_proba(X_lfr_test)[:, 1]},\n",
    "         title='LR', ax=ax[0]) \n",
    "plot_auc(y_test, \n",
    "         {'AUC biased': BiasedRfcModel.predict_proba(X_test)[:, 1],\n",
    "          'AUC fair': UnbiasedRfcModel.predict_proba(X_lfr_test)[:, 1]},\n",
    "         title='RFC', ax=ax[1]) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_importance(mod: Union[LogisticRegression, RandomForestClassifier], names: List[str],scale=None) -> pd.DataFrame:\n",
    "    \"\"\"Return feature importance for LR or RFC models in a sorted DataFrame.\"\"\"\n",
    "    if type(mod) == LogisticRegression:\n",
    "        imp = np.abs(mod.coef_.squeeze()) / scale\n",
    "        var = np.zeros(shape=imp.shape)\n",
    "    elif type(mod) == RandomForestClassifier:\n",
    "        imps = np.array([fi.feature_importances_ for fi in mod.estimators_])\n",
    "        imp = imps.mean(axis=0)\n",
    "        var = imps.std(axis=0)\n",
    "\n",
    "    return pd.DataFrame({'feature': names, 'importance': imp,\n",
    "                         'std': var}).sort_values('importance', ascending=False)\n",
    "\n",
    "def plot_feature_importance(**kwargs) -> None:\n",
    "    ax = sns.barplot(**kwargs)\n",
    "    for l in ax.get_xticklabels():\n",
    "        l.set_rotation(90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(16, 6))\n",
    "\n",
    "plot_feature_importance(x='feature', y='importance', \n",
    "                        data=feature_importance(BiasedLogModel, names=X_train.columns.tolist(),\n",
    "                                                scale=X_train.std()), ax=ax[0])\n",
    "_ = ax[0].set_title('LR Feature Importance - biased')\n",
    "plot_feature_importance(x='feature', y='importance', \n",
    "                        data=feature_importance(BiasedRfcModel, names=X_train.columns.tolist()), ax=ax[1])\n",
    "_ = ax[1].set_title('RFC Feature Importance - biased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(16, 6))\n",
    "\n",
    "plot_feature_importance(x='feature', y='importance', \n",
    "                        data=feature_importance(UnbiasedLogModel, names=X_lfr_train.columns.tolist(), \n",
    "                                                scale=X_lfr_train.std()), ax=ax[0])\n",
    "_ = ax[0].set_title('LR Feature Importance - fair')\n",
    "plot_feature_importance(x='feature', y='importance', \n",
    "                        data=feature_importance(UnbiasedRfcModel, names=X_lfr_train.columns.tolist()), ax=ax[1])\n",
    "_ = ax[1].set_title('RFC Feature Importance - fair')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_metrics(mod, x: pd.DataFrame, y_true: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Calculate fairness metrics at each model threshold.\"\"\"\n",
    "    \n",
    "    # Create a BinaryLabelDataset (as before training)\n",
    "    bld = BinaryLabelDataset(df=pd.concat((x, y_true), axis=1),label_names=[lab],\n",
    "                                  protected_attribute_names=[protected_attr],\n",
    "                                  favorable_label=fav_label, unfavorable_label=unfav_label)\n",
    "\n",
    "    # Create a second set to hold the predicted labels\n",
    "    bld_preds = bld.copy(deepcopy=True)\n",
    "    preds = mod.predict_proba(x)[:, 1] # for all the rows, retain the 2nd value.\n",
    "                                       # preds will contain a single column table of all \n",
    "                                       # probabilities that the classification will be 1.\n",
    "    accuracy          = []\n",
    "    balanced_accuracy = []\n",
    "    disp_impact       = []\n",
    "    average_abs_odds_difference = []\n",
    "    avg_odd_diff = []\n",
    "    equal_opportunity_difference = []\n",
    "    error_rate = []\n",
    "    \n",
    "    # For threshold values between 0 and 1:\n",
    "    thresh = np.linspace(0.01, 0.99, 100) # generate 100 evenly spaced values from 0.01->0.99 \n",
    "    for t in thresh:\n",
    "        \n",
    "        # Apply threshold and set labels in bld for predictions\n",
    "        bld_preds.labels[preds > t] = 1  # labels is a structured dataset attribute.\n",
    "        bld_preds.labels[preds <= t] = 0\n",
    "\n",
    "        # Calculate the metrics for this threshold\n",
    "        valid_metric = ClassificationMetric(bld, bld_preds, \n",
    "                                            unprivileged_groups=unprivileged_groups,\n",
    "                                            privileged_groups=privileged_groups)\n",
    "\n",
    "        # Save the balanced accuracy of the model, and the metrics\n",
    "        accuracy.append(valid_metric.accuracy())\n",
    "        balanced_accuracy.append(0.5 * (valid_metric.true_positive_rate()\n",
    "                                        + valid_metric.true_negative_rate()))\n",
    "#        disp_impact.append(np.abs(valid_metric.disparate_impact() - 0.5))\n",
    "        disp_impact.append(np.abs(valid_metric.disparate_impact()))\n",
    "        average_abs_odds_difference.append(valid_metric.average_abs_odds_difference())\n",
    "        avg_odd_diff.append(valid_metric.average_odds_difference())\n",
    "        equal_opportunity_difference.append(valid_metric.equal_opportunity_difference())\n",
    "        error_rate.append(valid_metric.error_rate())\n",
    "\n",
    "    # Return as df indexed by threshold\n",
    "    metrics = pd.DataFrame({'accuracy': accuracy,\n",
    "                            'balanced_accuracy': balanced_accuracy,\n",
    "                            'disparate_impact': disp_impact,\n",
    "                            'average_abs_odds_difference': average_abs_odds_difference,\n",
    "                            'avg_odds_diff': avg_odd_diff,\n",
    "                            'equal_opportunity_diff': equal_opportunity_difference},\n",
    "                            index=thresh)\n",
    "#'error_rate': error_rate},\n",
    "    return metrics\n",
    "\n",
    "\n",
    "def plot_metrics(metrics: pd.DataFrame, \n",
    "                 title: str='', **kwargs) -> None:\n",
    "    \"\"\"Plot the metrics df from calc_metrics with seaborn.\"\"\"\n",
    "    ax = sns.lineplot(data=metrics, \n",
    "                      **kwargs)\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel('Classification threshold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot for Logistic Regression Classifier\n",
    "%matplotlib inline\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(16,6))\n",
    "with warnings.catch_warnings():\n",
    "     warnings.simplefilter('ignore', RuntimeWarning)\n",
    "    \n",
    "     plot_metrics(calc_metrics(BiasedLogModel, X_test, y_test), ax=ax[0], title=\"LR: Biased\")\n",
    " \n",
    "     plot_metrics(calc_metrics(UnbiasedLogModel, X_lfr_test, y_lfr_test), ax=ax[1], title=\"LR: Fair\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot for Random Forest Classifier\n",
    "%matplotlib inline\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(16, 6))\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter('ignore', RuntimeWarning)\n",
    "    \n",
    "    plot_metrics(calc_metrics(BiasedRfcModel, X_test, y_test), ax=ax[0], title=\"RFC: Biased\")\n",
    "    \n",
    "    plot_metrics(calc_metrics(UnbiasedRfcModel, X_lfr_test, y_lfr_test), ax=ax[1], title=\"RFC: Fair\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(\"#### Individual fairness metrics\"))\n",
    "print(\"Consistency of labels in transformed training dataset= %f\" %metric_train_lfr.consistency())\n",
    "print(\"Consistency of labels in original training dataset= %f\" %metric_train_bld.consistency())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check whether the transform on the original dataset has worked. \n",
    "# A false means that the dataset is transformed.\n",
    "Adult_train_lfr_df.equals(Adult_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Adult_train_df     = Adult_train_df.reset_index(drop=True)\n",
    "Adult_train_lfr_df = Adult_train_lfr_df.reset_index(drop=True)\n",
    "AdultBool          = (Adult_train_df != Adult_train_lfr_df).stack()  # Create Frame of comparison booleans\n",
    "Adultdiff          = pd.concat([Adult_train_df.stack()[AdultBool], Adult_train_lfr_df.stack()[AdultBool]], axis=1)\n",
    "Adultdiff.columns  =[\"Adult_train_df\", \"Adult_train_lfr\"]\n",
    "print(Adultdiff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## PCA Analysis of consitency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# At this stage the transformed dataframe will have the last threshold encountered!\n",
    "feat_cols = Adult_train_bld.feature_names\n",
    "\n",
    "orig_df = pd.DataFrame(Adult_train_bld.features,columns=feat_cols)\n",
    "orig_df['label'] = Adult_train_bld.labels\n",
    "orig_df['label'] = orig_df['label'].apply(lambda i: str(i))\n",
    "\n",
    "transf_df = pd.DataFrame(Adult_train_lfr.features,columns=feat_cols)\n",
    "transf_df['label'] = Adult_train_lfr.labels\n",
    "transf_df['label'] = transf_df['label'].apply(lambda i: str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "orig_pca = PCA(n_components=3)\n",
    "orig_pca_result = orig_pca.fit_transform(orig_df[feat_cols].values)\n",
    "\n",
    "orig_df['pca-one'] = orig_pca_result[:,0]\n",
    "orig_df['pca-two'] = orig_pca_result[:,1] \n",
    "orig_df['pca-three'] = orig_pca_result[:,2]\n",
    "\n",
    "display(Markdown(\"#### Original training dataset\"))\n",
    "print('Explained variation per principal component:')\n",
    "print(orig_pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transf_pca = PCA(n_components=3)\n",
    "transf_pca_result = transf_pca.fit_transform(transf_df[feat_cols].values)\n",
    "\n",
    "transf_df['pca-one'] = transf_pca_result[:,0]\n",
    "transf_df['pca-two'] = transf_pca_result[:,1] \n",
    "transf_df['pca-three'] = transf_pca_result[:,2]\n",
    "\n",
    "display(Markdown(\"#### Transformed training dataset\"))\n",
    "print('Explained variation per principal component:')\n",
    "print(transf_pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Load, clean up original test data and compute metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(\"#### Testing Dataset shape\"))\n",
    "print(Adult_test_bld.features.shape)\n",
    "\n",
    "metric_test_bld = BinaryLabelDatasetMetric(Adult_test_bld, \n",
    "                                            unprivileged_groups=unprivileged_groups,\n",
    "                                            privileged_groups=privileged_groups)\n",
    "display(Markdown(\"#### Original test dataset\"))\n",
    "print(\"Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_test_bld.mean_difference())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Transform test data and compute metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Adult_test_lfr = TR.transform(Adult_test_bld, threshold=threshold)\n",
    "metric_test_lfr = BinaryLabelDatasetMetric(Adult_test_lfr, \n",
    "                                         unprivileged_groups=unprivileged_groups,\n",
    "                                         privileged_groups=privileged_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Consistency of labels in tranformed test dataset= %f\" %metric_test_lfr.consistency())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Consistency of labels in original test dataset= %f\" %metric_test_bld.consistency())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_algorithm_success():\n",
    "#   \"\"\"Transformed dataset consistency should be greater than original dataset.\"\"\"\n",
    "    assert metric_test_lfr.consistency() > metric_test_bld.consistency(), \"Transformed dataset consistency should be greater than original dataset.\"\n",
    "print(check_algorithm_success())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Is it possible to predict the Sensitive Variable from the transformed dataset\n",
    "X_se_train = Adult_train_lfr_df.drop(protected_attr,axis=1)\n",
    "y_se_train = Adult_train_lfr_df[protected_attr]\n",
    "X_se_test  = Adult_test_df.drop(protected_attr,axis=1)\n",
    "y_se_test  = Adult_test_df[protected_attr]\n",
    "Se_UnbiasedLogModel = LogisticRegression(random_state=101)\n",
    "Se_UnbiasedRfcModel = RandomForestClassifier(n_estimators=100,max_depth=4,random_state=101)\n",
    "Se_UnbiasedLogModel.fit(X_se_train, y_se_train) \n",
    "Se_UnbiasedRfcModel.fit(X_se_train, y_se_train) \n",
    "yseLog_pred =  Se_UnbiasedLogModel.predict(X_se_test)\n",
    "yseRfc_pred =  Se_UnbiasedRfcModel.predict(X_se_test)\n",
    "# Now test whether we can predict Gender from the test dataset\n",
    "print('Model Accuracy for predicting the Sensitive Variable before bias transformation:')\n",
    "print(f\"Biased Logistic regression validation accuracy: {Se_UnbiasedLogModel.score(X_se_test, y_se_test)}\")\n",
    "print(f\"Biased Random Forest       validation accuracy: {Se_UnbiasedRfcModel.score(X_se_test, y_se_test)}\")\n",
    "print('')\n",
    "print('Biased Balanced accuracy')\n",
    "print(f\"Biased Logistic regression balanced accuracy  : {balanced_accuracy_score(y_se_test, yseLog_pred)}\")\n",
    "print(f\"Biased Random Forest       balanced accuracy  : {balanced_accuracy_score(y_se_test, yseRfc_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lastly get the number of labels from the training dataset\n",
    "print('Train df After - Income value counts:')\n",
    "print(Adult_train_lfr_df.Income.value_counts())\n",
    "print('Train df After - Gender value counts:')\n",
    "print(Adult_train_lfr_df.Gender.value_counts())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
